% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/CBFM.R
\name{CBFM}
\alias{CBFM}
\title{Community-level basis function models (CBFMs)}
\usage{
CBFM(
  y,
  formula,
  ziformula = NULL,
  data,
  B_space = NULL,
  B_time = NULL,
  B_spacetime = NULL,
  offset = NULL,
  ncores = NULL,
  family = stats::gaussian(),
  trial_size = 1,
  dofit = TRUE,
  stderrors = TRUE,
  select = FALSE,
  gamma = 1,
  ziselect = FALSE,
  zigamma = 1,
  nonzeromean_B_space = FALSE,
  nonzeromean_B_time = FALSE,
  nonzeromean_B_spacetime = FALSE,
  start_params = list(betas = NULL, zibetas = NULL, basis_effects_mat = NULL, dispparam
    = NULL, powerparam = NULL),
  TMB_directories = list(cpp = system.file("executables", package = "CBFM"), compile =
    system.file("executables", package = "CBFM")),
  control = list(maxit = 100, inner_maxit = 1, optim_lower = -50, optim_upper = 50,
    convergence_type = "parameters_MSE", tol = 1e-04, final_maxit = 100,
    initial_beta_dampen = 1, subsequent_betas_dampen = 0.25, gam_method = "REML", seed =
    NULL, ridge = 0, ziridge = 0, trace = 0),
  Sigma_control = list(rank = 5, maxit = 100, tol = 1e-04, method = "REML", trace = 0,
    custom_space = NULL, custom_time = NULL, custom_spactime = NULL),
  G_control = list(rank = 5, structure = "unstructured", nugget_profile = seq(0.05,
    0.95, by = 0.05), maxit = 100, tol = 1e-04, method = "REML", trace = 0, custom_space =
    NULL, custom_time = NULL, custom_spactime = NULL, min_sp = 0),
  k_check_control = list(subsample = 5000, n.rep = 400)
)
}
\arguments{
\item{y}{A response matrix, where each row corresponds to an observational unit \eqn{i}.e, a particular space-time coordinate, and each column corresponds to a species.}

\item{formula}{An object of class "formula", which represents a symbolic description of the model matrix to be created (based on using this argument along with the \code{data} argument). Note there should be nothing on the left hand side of the "~". Formulas based on generalized additive models or GAMs are permitted (at least, for the basic smoothing terms we have tried so far!); please see \code{\link[mgcv:formula.gam]{mgcv::formula.gam()}}, \code{\link[mgcv:gam.models]{mgcv::gam.models()}}, \code{\link[mgcv:smooth.terms]{mgcv::smooth.terms()}}, and \code{\link[mgcv:s]{mgcv::s()}} for more details.}

\item{ziformula}{An object of class "formula", which represents a symbolic description of the model matrix to be created for the zero-inflation component (based on using this argument along with the \code{data} argument), if appropriate. Note there should be nothing on the left hand side of the "~". Formulas based on generalized additive models or GAMs are permitted (at least, for #' @param data A data frame containing covariate information, from which the model matrix is to be created (based on this argument along with the \code{formula} argument}

\item{data}{A data frame containing covariate information, from which the model matrix is to be created (based on this argument along with the \code{formula} argument).}

\item{B_space}{An optional matrix of spatial basis functions to be included in the CBFM. One of \code{B_space}, \code{B_time}, or \code{B_spacetime} must be supplied. The basis function matrix may be sparse or dense in form; please see the details and examples later on for illustrations of how they can constructed.}

\item{B_time}{An optional of matrix of temporal basis functions to be included in the CBFM. One of \code{B_space}, \code{B_time}, or \code{B_spacetime} must be supplied. The basis function matrix may be sparse or dense in form; please see the details and examples later on for illustrations of how they can constructed.}

\item{B_spacetime}{An optional of matrix of spatio-temporal basis functions to be included in the CBFM e.g., formed from a tensor-product of spatial and temporal basis functions. One of \code{B_space}, \code{B_time}, or \code{B_spacetime} must be supplied. The basis function matrix may be sparse or dense in form; please see the details and examples later on for illustrations of how they can constructed.}

\item{offset}{A matrix of offset terms.}

\item{ncores}{To speed up fitting, parallelization can be performed, in which case this argument can be used to supply the number of cores to use in the parallelization. Defaults to \code{detectCores()-1}.}

\item{family}{a description of the response distribution to be used in the model, as specified by a family function. Please see details below for more information on the distributions currently permitted.}

\item{trial_size}{Trial sizes to use for binomial distribution. This can either equal a scalar or a matrix with the same dimension as \code{y}.}

\item{dofit}{Should the CBFM be fitted? If set to \code{FALSE}, then the function terminates (and return nothing) immediately after copying the C++ file to the compilation directory; please see the \code{TMB_directories} argument below.}

\item{stderrors}{Should standard errors of the estimates be calculated? This defaults to \code{TRUE}, but can be set of \code{FALSE} if only point estimations of the regression coefficients for the covariates and basis functions are desired. Please see details later on for more information on how standard errors are constructed.}

\item{select}{For cases where \code{formula} involves smoothing terms, setting this to \code{TRUE} adds an extra penalty to each smoothing term so that it can be penalized to zero i.e., null space penalization. Please see \code{\link[mgcv:gam.selection]{mgcv::gam.selection()}} and \code{\link[mgcv:step.gam]{mgcv::step.gam()}} for more details, noting that its implementation for the purposes of CBFM is a \emph{wee bit experimental}. Note this argument has no effect on any parametric terms in the model i.e., it can not shrink parametric terms to zero.}

\item{gamma}{For cases where \code{formula} involves smoothing terms, setting this to a value greater than one leads to smoother terms i.e., increased penalization. Note the argument can either be set to a scalar, or a vector with length equal to the number of species i.e., \code{ncol(y)}. This argument plays exactly the same role as the \code{gamma} argument in \code{\link[mgcv:gam]{mgcv::gam()}}, and we refer to the help file for more information. As with the \code{select} argument, its implementation for the purposes of CBFM is a \emph{wee bit experimental}. Finally, note this argument has no effect on any parametric terms or the basis functions part of the CBFM.}

\item{ziselect}{For cases where \code{ziformula} involves smoothing terms, setting this to \code{TRUE} adds an extra penalty to each smoothing term so that it can be penalized to zero i.e., null space penalization. Please see \code{\link[mgcv:gam.selection]{mgcv::gam.selection()}} and \code{\link[mgcv:step.gam]{mgcv::step.gam()}} for more details, noting that its implementation for the purposes of CBFM is a \emph{wee bit experimental}. Note this argument has no effect on any parametric terms in the model i.e., it can not shrink parametric terms to zero.}

\item{zigamma}{For cases where \code{ziformula} involves smoothing terms, setting this to a value greater than one leads to smoother terms i.e., increased penalization. Note the argument can either be set to a scalar, or a vector with length equal to the number of species i.e., \code{ncol(y)}. This argument plays exactly the same role as the \code{gamma} argument in \code{\link[mgcv:gam]{mgcv::gam()}}, and we refer to the help file for more information. As with the \code{select} argument, its implementation for the purposes of CBFM is a \emph{wee bit experimental}. Finally, note this argument has no effect on any parametric terms or the basis functions part of the CBFM.}

\item{nonzeromean_B_space}{This is an experimental feature that allows the distribution of the spatial basis function coefficients to have a non-zero mean vector. \emph{Please leave it as it as at the moment i.e., set to \code{FALSE}!}}

\item{nonzeromean_B_time}{This is an experimental feature that allows the distribution of the temporal basis function coefficients to have a non-zero mean vector. \emph{Please leave it as it as at the moment i.e., set to \code{FALSE}!}}

\item{nonzeromean_B_spacetime}{This is an experimental feature that allows the distribution of the spatio-temporal basis function coefficients to have a non-zero mean vector. \emph{Please leave it as it as at the moment i.e., set to \code{FALSE}!}}

\item{start_params}{Starting values for the CBFM. If desired, then a list should be supplied, which must contain at least one the following terms:
\itemize{
\item{betas: }{A matrix of starting values for the species-specific regression coefficients related to the covariates, where the number of rows is equal to the number of species.}
\item{zibetas: }{A matrix of starting values for the species-specific regression coefficients related to the covariates for the zero-inflation component (if included), where the number of rows is equal to the number of species.}
\item{basis_effect_mat: }{A matrix of starting values for the species-specific regression coefficients related to the combined matrix of basis functions. Again, the number of rows is equal to the number of species, while the number of columns should equal to \code{ncol(B_space, B_time, B_spacetime)} (or whatever the supplied basis functions are).}
\item{dispparam: }{A vector of starting values for the species-specific dispersion parameters, to be used for distributions that require one.}
\item{powerparam: }{A vector of starting values for the species-specific power parameters, to be used for distributions that require one.}
}}

\item{TMB_directories}{A list with two elements, identifying the directory where TMB C++ file exists (\code{cpp}), and the directory where the corresponding compiled files to be placed (\code{compile}). Unless you really want to do some real mucking around, these should be left at their default i.e., the directory where the packages were installed locally. Please note a version of the C++ file will be copied to the \code{compile} directory.}

\item{control}{A list of parameters for controlling the fitting process for the "outer" PQL estimation part of the CBFM. This should be a list with the following arguments:
\itemize{
\item{maxit: }{The maximum number of iterations for the outer algorithm. Defaults to 100.}
\item{inner_maxit: }{The maximum number of iterations for the inner (EM) algorithm. Defaults to 1, although it is recommended that this is tested out and increased if convergence presents as an issue.}
\item{optim_lower/optim_upper: }{Upper and lower box constraints when updating regression coefficients related to the basis functions. Note no constraints are put in place when updating regression coefficients related to the covariates; this are controlled internally by \code{\link[mgcv:gam.control]{mgcv::gam.control()}} itself.}
\item{convergence_type: }{The type of means by which to assess convergence. The current options are "parameters_MSE" (default), which assesses convergence based on the mean squared error of the difference between estimated parameters from successive iterations, "parameters_norm" which assesses convergence based on the sum of the squared error (i.e., the squared norm) of the difference between estimated parameters from successive iterations, "parameters_relative" which assesses convergence based on the relative change in mean squared error of the difference between estimated parameters from successive iterations, and "logLik_relative", which assess convergence based on the relative change in the PQL value between successive iterations.

Although the first option is employed as a default, the second and third choices are often used in to assess convergence in other, likelihood-based optimization problems (e.g., Green, 1984).}
\item{tol: }{The tolerance value to use when assessing convergence.}
\item{final_maxit: }{The maximum number of iterations to do for the final estimation step after the PQL algorithm has converged. }
\item{initial_betas_dampen: }{A dampening factor which can be used to reduce the magnitudes of the starting values obtained for the species-specific regression coefficients corresponding to the model matrix i.e., \code{betas}. This can either be set to a scalar, or a vector with length equal to the number of species i.e., \code{ncol(y)}.
To elaborate, when starting values are not supplied as part of \code{start_params}, the function will attempt to obtain starting values based on fitting a stacked species distribution model. While this generally works OK, sometimes it can lead to bad starting values for the \code{betas}, due to the stacked species distribution model being severely overfitted. An \emph{ad-hoc} fix to this is to dampen/shrink these initial values to be closer to zero, thus allowing the PQL estimation algorithm to actually "work". For instance, setting \code{initial_betas_dampen = 0.8} means the magnitudes of the staring values for the \code{betas} are reduced to 0.8 of their full values. This includes the species-specific intercepts.
When \code{initial_betas_dampen} is a vector, then the dampening factor can vary with species.}
\item{subsequent_betas_dampen: }{A dampening factor which can be used to reduce the magnitudes of the values obtained for the species-specific regression coefficients corresponding to the model matrix i.e., \code{betas}, during the running of the PQL estimation algorithm. This can either be set to a scalar, or a vector with length equal to the number of species i.e., \code{ncol(y)}.
To elaborate, during the PQL algorithm updates are made to the regression coefficients related to the combined matrix of basis functions, conditional on the regression coefficients corresponding to the model matrix. However, sometimes this updating can fails due to the latter producing non-sensible values to condition on e.g., due to severe overfitting in that component. If this occurs, then an \emph{ad-hoc} second attempt is made, but conditioning instead on a dampened/shrunk set of the regression coefficients corresponding to the model matrix, which can often help. This amount of dampening is controlled by this argument. For instance, setting \code{subsequent_betas_dampen = 0.25} sets the magnitudes of the regression coefficients related to the model matrix to a quarter of their original size, including the intercepts.
When \code{subsequent_betas_dampen} is a vector, then the dampening factor can vary with species.
Note that this argument \emph{only} comes into play when the first attempt, which can be thought of as updating with \code{subsequent_betas_dampen = 1}, to update the regression coefficients associated with the combined matrix of basis functions fails. }
\item{gam_method: }{When smoothing terms are included in the model, this controls the smoothing parameter estimation method. Defaults to "REML", which is maximum restricted likelihood estimation. However other options are available; please see the \code{method} argument in \code{\link[mgcv:gam]{mgcv::gam()}} for the available options. In fact, note that \code{\link[mgcv:gam]{mgcv::gam()}} defaults to using "GCV.Cp", which is based on generalzed cross-validation. This is generally faster, but can be slightly more unstable, and hence why restricted maximum likelihood estimation is adopted as the default. }
\item{seed: }{The seed to use for the PQL algorithm. This is only applicable when the starting values are randomly generated, which be default should not be the case.}
\item{ridge: }{A additional ridge parameter that can be included to act as a ridge penalty when estimating the regression coefficients related to the covariates.}
\item{ziridge: }{A additional ridge parameter that can be included to act as a ridge penalty when estimating the regression coefficients related to the covariates for modeling the zero-inflation probabilities.}
\item{trace: }{If set to \code{TRUE} or \code{1}, then information at each iteration step of the outer algorithm will be printed. }
}}

\item{Sigma_control}{A list of parameters for controlling the fitting process for the "inner" estimation part of the CBFM pertaining to the community-level covariance matrices of the basis function regression coefficients. This should be a list with the following arguments:
\itemize{
\item{rank: }{The rank of the community-level covariance matrices of the basis function regression coefficients. This either equals to a single scalar/character string equal to "full", or a vector or scalars/character strings (equal to "full") with length equal to how many of \code{B_space/B_time/B_spacetime} are supplied. If it is a single scalar or character string, then it is assumed that the same rank is used for all the community-level covariance matrices.

The rank/s should be at least 2, although internal checks are also performed to assess if the rank is too large so that estimation is not feasible. If the character string "full" is used, then a full-rank covariance matrix is estimated.}
\item{maxit: }{The maximum number of iterations for inner update of the community-level covariance matrices.}
\item{tol: }{The tolerance value to use when assessing convergence. Convergence for the inner algorithm is assessed based on the norm of the difference between estimated parameters from successive iterations.}
\item{method: }{The method by which to update the community-level covariance matrices. The current options are "REML" (default) which uses optimizing the Laplace approximated restricted maximum likelihood, "ML" which is the same but with the Laplace approximated (unrestricted) maximum likelihood, and "simple" which uses a fast large sample covariance update. \emph{Note that the simple method is faster than the former, but is \emph{much} less accurate and we only recommend using it for pilot testing.}}
\item{trace: }{If set to \code{TRUE} or \code{1}, then information at each iteration step of the inner algorithm will be printed.}
\item{custom_space: }{A custom, pre-specified community-level matrix for the spatial basis function regression can be supplied. If supplied, it must be a square matrix with dimension equal to the number of columns in \code{B_space}. Defaults to \code{NULL}, in which case it is estimated. Note as a side quirk, if this argument is supplied then a corresponding rank (as above) still has to be supplied, even though it is not used.}
\item{custom_time: }{A custom, pre-specified community-level covariance matrix for the temporal basis function regression can be supplied. If supplied, it must be a square matrix with dimension equal to the number of columns in \code{B_time}. Defaults to \code{NULL}, in which case it is estimated. Note as a side quirk, if this argument is supplied then a corresponding rank (as above) still has to be supplied, even though it is not used.}
\item{custom_spacetime: }{A custom, pre-specified community-level covariance matrix for the spatio-temporal basis function regression can be supplied. If supplied, it must be a square matrix with dimension equal to the number of columns in \code{B_spacetime}. Defaults to \code{NULL}, in which case it is estimated. Note as a side quirk, if this argument is supplied then a corresponding rank (as above) still has to be supplied, even though it is not used.}
}}

\item{G_control}{A list of parameters for controlling the fitting process for the "inner" estimation part of the CBFM pertaining to the so-called baseline between-species correlation matrices of the basis function regression coefficients. This should be a list with the following arguments:
\itemize{
\item{rank}{The rank of the between-species correlation matrices of the basis function regression coefficients. This either equals to a single scalar/character string equal to "full", or a vector or scalars/character strings (equal to "full") with length equal to how many of \code{B_space/B_time/B_spacetime} are supplied. If it is a scalar, then it is assumed that the same rank is used for all the correlation matrices.

The rank/s should be at least 2, although internal checks are also performed to assess if the rank is too large so that estimation is not feasible. If the character string "full" is used, then a full-rank correlation matrix is estimated.

Finally. note if a particular element in \code{G_control$structure} is set to "identity", then a corresponding element in \code{G_control$rank} must still be supplied, but it is ignored.}
\item{structure: }{The structure to assume for the between-species correlation matrix if it is estimated. This either equals to a single character string or a vector of character strings with length equal to how many of \code{B_space/B_time/B_spacetime} are supplied. If it is a single string, then it is assumed that the same form is used for all the correlation matrices. The current options for each element are "unstructured" (default) which assumes an unstructured form subject to the corresponding element in \code{G_control$rank}, and "identity" which assumes a constant multiplied by an identity matrix. The latter should \emph{not} be used unless you know what are doing in terms of what you want to achieve from the basis functions.}
\item{nugget_profile: }{The sequence of values to try for calculating the nugget effect in each between-species correlation matrix. Please see details below for more information.}
\item{maxit: }{The maximum number of iterations for inner update of the community-level covariance matrices.}
\item{tol: }{The tolerance value to use when assessing convergence. Convergence for the inner algorithm is assessed based on the norm of the difference between estimated parameters from successive iterations.}
\item{method: }{The method by which to update the community-level covariance matrices. The current options are "REML" (default) which uses optimizing the Laplace approximated restricted maximum likelihood, "ML" which is the same but with the Laplace approximated (unrestricted) maximum likelihood, and "simple" which uses a fast large sample covariance update. \emph{Note that the simple method is faster than the former, but is \emph{much} less accurate and we only recommend using it for pilot testing.}}
\item{trace: }{If set to \code{TRUE} or \code{1}, then information at each iteration step of the inner algorithm will be printed.}
\item{custom_space: }{A custom, pre-specified baseline between-species correlation matrix for the spatial basis function regression can be supplied. If supplied, it must be a square matrix with dimension equal to the number of columns in \code{B_space}. Defaults to \code{NULL}, in which case it is estimated. Note as a side quirk, if this argument is supplied then a corresponding rank (as above) still has to be supplied, even though it is not used.}
\item{custom_time: }{A custom, pre-specified between-species correlation matrix matrix for the temporal basis function regression can be supplied. If supplied, it must be a square matrix with dimension equal to the number of columns in \code{B_time}. Defaults to \code{NULL}, in which case it is estimated. Note as a side quirk, if this argument is supplied then a corresponding rank (as above) still has to be supplied, even though it is not used.}
\item{custom_spacetime: }{A custom, pre-specified between-species correlation matrix matrix for the spatio-temporal basis function regression can be supplied. If supplied, it must be a square matrix with dimension equal to the number of columns in \code{B_spacetime}. Defaults to \code{NULL}, in which case it is estimated. Note as a side quirk, if this argument is supplied then a corresponding rank (as above) still has to be supplied, even though it is not used.}
\item{min_sp: }{This is an experimental feature that, when a particular \code{G_control$structure} is set to "identity", allows a minimum amount of smoothing to be applied to the corresponding basis function coefficients. Similar to \code{G_control$rank} and \code{G_control$structure}, this either equals to a single character string or a vector of character strings with length equal to how many of \code{B_space/B_time/B_spacetime} are supplied. If it is a single string, then it is assumed that the same form is used for all the correlation matrices.

Note if a particular element in \code{G_control$structure} is set to "unstructured", then a corresponding element in \code{G_control$min_sp} must still be supplied, but it is ignored.

\emph{Please leave it as it as at the moment i.e., set to 0!}}
}}

\item{k_check_control}{A list of parameters for controlling \code{\link[mgcv:k.check]{mgcv::k.check()}} when it is applied to CBFMs involving smoothing terms for the measured covariates i.e., when smoothing terms are involved in \code{formula}. Please see \code{\link[mgcv:k.check]{mgcv::k.check()}} for more details on how this test works. This should be a list with the following two arguments:
\itemize{
\item{subsample: }{If the number of observational units i.e., \code{nrow(y)} exceeds this number, then testing is done using a random sub-sample of units of this size.}
\item{n.rep: }{How many re-shuffles of the residuals should be done in order to a P-value for testing. }
}}
}
\value{
An object of class \code{CBFM} which includes the following components, not necessarily in the order below (and as appropriate). Note outputs resulting from experimental input arguments are now itemized below:
\item{call: }{The matched function call.}
\item{family: }{The supplied response distribution i.e., family function, to be used in the model.}
\item{y, data, trial_size: }{The supplied response matrix, covariate information data frame, and trial size(s).}
\item{formula: }{The supplied symbolic description of the model matrix to be created.}
\item{ziformula: }{The supplied symbolic description of the model matrix to be created for modeling the probability of zero-inflation.}
\item{B: }{The full matrix basis functions i.e., basically the result of \code{cbind(B_space, B_time, B_spacetime)}.}
\item{which_B_used: }{A vector of length three, indicating which of \code{B_space, B_time, B_spacetime} was supplied. For example \code{which_B_bused = c(1,0,0)} implies only \code{B_space} was supplied.}
\item{num_B_space: }{The number of spatial basis functions supplied i.e., \code{ncol(B_space)}.}
\item{num_B_time: }{The number of temporal basis functions supplied i.e., \code{ncol(B_time)}.}
\item{num_B_spacetime: }{The number of spatio-temporal basis functions supplied i.e., \code{ncol(B_spacetime)}.}
\item{num_B: }{The total number of basis functions supplied i.e., \code{ncol(cbind(B_space, B_time, B_spacetime))}.}
\item{converged: }{Indicates whether or not the PQL estimation algorithm converged. Note results may still be outputted (and sensible?!) even if this is \code{FALSE}.}
\item{logLik: }{The value of the log-likelihood (excluding the quadratic penalty term in the PQL) for the fitted model.}
\item{logLik_perspecies: }{The value of each species' contribution to the log-likelihood (excluding the quadratic penalty term in the PQL) for the fitted model.}
\item{deviance: }{The deviance for the fitted model. Note the deviance calculation here does \emph{not} include the quadratic term of the PQL.}
\item{deviance_perspecies: }{The value of each species' contribution to the deviance of the fitted model. Note the deviance calculation here does \emph{not} include the quadratic term of the PQL.}
\item{null_deviance: }{The null deviance i.e., deviance of a stacked model (GLM) where each species model contains only an intercept. Note the deviance calculation here does \emph{not} include the quadratic term of the PQL}
\item{null_deviance_perspecies: }{The value of each species' contribution to the null deviance. Note the deviance calculation here does \emph{not} include the quadratic term of the PQL}
\item{deviance_explained: }{The \emph{percentage} of null deviance explained by the model. In community ecology this is typically not very high (haha!); please see \code{\link[=varpart]{varpart()}} for more capacity to perform variance partitioning in a CBFM. This is constructed by examining \code{deviance} to \code{null_deviance}.}
\item{deviance_explained_perspecies: }{The \emph{percentage} of null deviance explained by the model, on a per-species basis. This is constructed by examining \code{deviance_perspecies} to \code{null_deviance_perspecies}.}
\item{pql_logLik: }{The value of the PQL i.e., the likelihood plus the quadratic penalty term, upon convergence.}
\item{edf/edf1: }{A matrix of estimated degrees of freedom for each model parameter in \code{formula}. The number of columns of the matrix should be equal to the number of species i.e., \code{ncol(y)}. Penalization means that many of these are less than one. \code{edf1} is an alternative estimate of EDF. Note these values are pulled straight from the GAM part of the estimation algorithm, and consequently may only be \emph{very} approximate. }
\item{ziedf/ziedf1: }{A matrix of estimated degrees of freedom for each model parameter in \code{ziformula}. The number of columns of the matrix should be equal to the number of species i.e., \code{ncol(y)}. Penalization means that many of these are less than one. \code{edf1} is an alternative estimate of EDF. Note these values are pulled straight from the GAM part of the estimation algorithm, and consequently may only be \emph{very} approximate. }
\item{pen_edf: }{A list with each element containing a vector of the estimated degrees of freedom associated with each smoothing term in \code{formula}. The length of the list should be equal to the number of species i.e., \code{ncol(y)}. Note these values are pulled straight from the GAM part of the estimation algorithm, and consequently may only be \emph{very} approximate.}
\item{zipen_edf: }{A list with each element containing a vector of the estimated degrees of freedom associated with each smoothing term in \code{ziformula}. The length of the list should be equal to the number of species i.e., \code{ncol(y)}. Note these values are pulled straight from the GAM part of the estimation algorithm, and consequently may only be \emph{very} approximate.}
\item{k_check: }{A list resulting from the application of \code{\link[mgcv:k.check]{mgcv::k.check()}}, used as a diagnostic test of whether the smooth basis dimension is adequate for smoothing terms included in \code{formula}, on a per-species basis. Please see \code{\link[mgcv:k.check]{mgcv::k.check()}} for more details on the test and the output. Note that if no smoothing terms are included in \code{formula}, then this will be a list of \code{NULL} elements.}
\item{vcomp: }{A list with length equal to \code{ncol(y)}, where each element contains a vector of the estimated variance components (as standard deviations) associated with the smoothing terms included in \code{formula}. This output is only really useful when one or more of the smoothing terms were included in the CBFM as species-specific intercepts/slopes (see \code{\link[mgcv:random.effects]{mgcv::random.effects()}} for more details), in which case the corresponding values in \code{vcomp} are the estimated variance components (estimated standard deviations to be precise) associated with these random effects; see \code{\link[mgcv:random.effects]{mgcv::random.effects()}} and \code{\link[mgcv:gam.vcomp]{mgcv::gam.vcomp()}} for more details on the one-to-one relationship between smoothing parameters in GAMs and variance components in mixed models. Note that if no smoothing terms are included in \code{formula}, then this will be a list of \code{NULL} elements.}
\item{betas: }{The estimated matrix of species-specific regression coefficients corresponding to the model matrix created. The number of rows in \code{betas} is equal to the number of species i.e., \code{ncol(y)}.}
\item{zibetas: }{The estimated matrix of species-specific regression coefficients corresponding to the model matrix created for the zero-inflation component. The number of rows in \code{zibetas} is equal to the number of species i.e., \code{ncol(y)}. Recall a logit scale to model the probability of zero-inflation i.e., \eqn{log(\pi/(1-\pi))} is regressed against covariates.}
\item{basis_effects_mat: }{The estimated matrix of species-specific regression coefficients corresponding to the combined matrix of basis functions. The number of rows in \code{basis_effects_mat} is equal to the number of species i.e., \code{ncol(y)}.}
\item{dispparam: }{The estimated vector of species-specific dispersion parameters, for distributions which require one. }
\item{powerparam: }{The estimated vector of species-specific power parameters, for distributions which require one. }
\item{linear_predictors: }{The estimated matrix of linear predictors. Note that for zero-inflated distributions, the mean of the count component is modeled in CBFM, and the function returns the linear predictors corresponding to this count component in the CBFM. Similarly, for zero-truncated count distributions, the mean of the base count distribution is modeled in CBFM, and the function returns the linear predictors corresponding to this base count distribution in the CBFM (and \code{NA} values for elements corresponding to zero counts in \code{object$y}.)}
\item{fitted: }{The estimated matrix of fitted mean values. Note that for zero-inflated distributions, while the mean of the count component is modeled in CBFM, the fitted values are the \emph{actual expected mean values} i.e., it returns estimated values of \eqn{(1-\pi_{ij})\mu_{ij}} where \eqn{\pi_j} is the species-specific probability of zero inflation and \eqn{\mu_{ij}} is the mean of the count component.
Similarly, for zero-truncated count distributions, while the mean of the base count distribution is modeled in CBFM, the fitted values are the \emph{actual expected mean values} i.e., it returns estimated values of \eqn{\mu_{ij}/(1-p(0,\mu_{ij}))} where \eqn{\mu_{ij}} is the mean of the base count distribution component and \eqn{p(0,\mu_{ij})} generically denotes the probability of observing a zero count for the base count distribution (and it returns \code{NA} values for elements corresponding to zero counts in \code{object$y}.)
}
\item{Sigma_space/Loading_Sigma_space/nugget_Sigma_space: }{The estimated community-level covariance matrix/loadings/nugget effect associated with the spatial basis functions, if \code{B_space} is supplied. Note if \code{Sigma_control$custom_space} was supplied, then \code{Sigma_space} would be directly the supplied matrix, while the loading and nugget arguments are set to \code{NULL}.}
\item{G_space/Loading_G_space/nugget_G_space: }{The estimated baseline between-species correlation matrix/loadings/nugget effect associated with the spatial basis functions, if \code{B_space} is supplied. Note if \code{Sigma_control$custom_space} was supplied, then a covariance matrix is estimated instead. Note if \code{G_control$custom_space} was supplied, then \code{G_space} would be directly the supplied matrix, while the loading and nugget arguments are set to \code{NULL}.}
\item{Sigma_time/Loading_Sigma_time/nugget_Sigma_time: }{The estimated community-level covariance matrix/loadings/nugget effect associated with the temporal basis functions, if \code{B_time} is supplied. Note if \code{Sigma_control$custom_time} was supplied, then \code{Sigma_time} would be directly the supplied matrix, while the loading and nugget arguments are set to \code{NULL}.}
\item{G_time/Loading_G_time/nugget_G_time: }{The estimated baseline between-species correlation matrix/loadings/nugget effect associated with the temporal basis functions, if \code{B_time} is supplied. Note if \code{Sigma_control$custom_tiem} was supplied, then a covariance matrix is estimated instead. Note if \code{G_control$custom_time} was supplied, then \code{G_time} would be directly the supplied matrix, while the loading and nugget arguments are set to \code{NULL}.}
\item{Sigma_spacetime/Loading_Sigma_spacetime/nugget_Sigma_spacetime: }{The estimated community-level covariance matrix/loadings/nugget effect associated with the spatio-temporal basis functions, if \code{B_spacetime} is supplied. Note if \code{Sigma_control$custom_spacetime} was supplied, then \code{Sigma_spacetime} would be directly the supplied matrix, while the loading and nugget arguments are set to \code{NULL}.}
\item{G_spacetime/Loading_G_spacetime/nugget_G_spacetime: }{The estimated baseline between-species correlation matrix/loadings/nugget effect associated with the spatio-temporal basis functions, if \code{B_spacetime} is supplied. Note if \code{Sigma_control$custom_spacetime} was supplied, then a covariance matrix is estimated instead. Note if \code{G_control$custom_spacetime} was supplied, then \code{G_spacetime} would be directly the supplied matrix, while the loading and nugget arguments are set to \code{NULL}.}
\item{stderrors: }{The supplied argument for \code{stderrors} i.e., whether standard errors were calculated.}
\item{covar_components: }{If \code{stderrors = TRUE}, then a list containing with the following components:
\enumerate{
\item \code{topleft}, which is a matrix corresponding to the top-left block of the full Bayesian posterior covariance matrix. The top-left block specifically relates to the regression coefficients associated with the measured predictors i.e., the covariance matrix associated with \code{object$betas}, along with \code{object$zibetas} if zero-inflated distributions are used;
\item \code{topright}, which is a matrix of the top-right block of the full Bayesian posterior covariance matrix. The top-right block specifically relates to the cross-covariance of the regression coefficients associated with the measured predictors (plus the coefficients associated with the probabilities of zero-inflation) and the basis functions i.e., the cross-covariance matrix between \code{object$betas} and \code{object$basis_effects_mat};
\item \code{bottomright}, which is a matrix containing components of the bottom-right block of the full Bayesian posterior covariance matrix. The bottom-left block specifically relates to the regression coefficients associated with the basis functions i.e., the covariance matrix associated with \code{object$basis_effects_mat}.
}

Please use the \code{\link[=summary.CBFM]{summary.CBFM()}} function to obtain standard errors and confidence interval limits in a (slightly) more user-friendly form.}
\item{all_parametric_effects: }{If \code{formula} included any parametric terms excluding the intercept, then a long format data frame is returned containing each estimated parametric effect for each species, which is then primarily used for visualizing the estimated parametric model terms. The data frame is effectively constructed by applying \code{\link[gratia:parametric_effects]{gratia::parametric_effects()}} for each species. If no smoothing terms are included in \code{formula}, then this will equal to \code{NULL}.}
\item{allzi_parametric_effects: }{If \code{ziformula} included any parametric terms excluding the intercept, then a long format data frame is returned containing each estimated parametric effect for each species in relation to the probability of zero-inflation, which is then primarily used for visualizing the estimated parametric model terms. The data frame is effectively constructed by applying \code{\link[gratia:parametric_effects]{gratia::parametric_effects()}} for each species. If no smoothing terms are included in \code{ziformula}, then this will equal to \code{NULL}.}
\item{all_smooth_estimates: }{If \code{formula} included any smoothing terms excluding the intercept, then a long format data frame is returned containing each estimated smoothed effect (evaluated on a grid of evenly spaced values over the range of each corresponding covariate) for each species, which is then primarily used for visualizing the smooth model terms. The data frame is effectively constructed by applying \code{\link[gratia:smooth_estimates]{gratia::smooth_estimates()}} for each species. If no smoothing terms are included in \code{formula}, then this will equal to \code{NULL}.}
\item{allzi_smooth_estimates: }{If \code{ziformula} included any smoothing terms excluding the intercept, then a long format data frame is returned containing each estimated smoothed effect (evaluated on a grid of evenly spaced values over the range of each corresponding covariate) for each species in relation to the probability of zero-inflation, which is then primarily used for visualizing the smooth model terms. The data frame is effectively constructed by applying \code{\link[gratia:smooth_estimates]{gratia::smooth_estimates()}} for each species. If no smoothing terms are included in \code{ziformula}, then this will equal to \code{NULL}.}
\item{time_taken: }{The time taken to run the PQL estimation algorithm, in seconds. This is calculated simply using differences in calls of \code{\link[base:proc.time]{base::proc.time()}}.}
}
\description{
\verb{r lifecycle::badge("experimental")}

Fits CBFMs to spatio-temporal multivariate abundance data, where the basis functions are used to account for spatio-temporal correlation within and between-species. Three types of basis functions can supplied and included in conjunction with each other: 1) spatial basis functions; 2) temporal basis functions; 3) spatio-temporal basis functions. For the part of the mean model corresponding to the measured covariates, CBFM currently permits both parametric terms and/or smoothing terms, where the latter makes use are included in a similar manner to \code{\link[mgcv:gam]{mgcv::gam()}}. Estimation and inference for CBFM is based on a maximum penalized quasi-likelihood (PQL) estimation approach.
}
\details{
Community-level basis function models (CBFMs) are a class of joint species distribution models for spatio-temporal multivariate abundance data, which builds on the ideas of fixed rank kriging (FRK, Cressie and Johannesson, 2008; Zammit-Mangion and Cressie, 2017) and multivariate spatio-temporal mixed models (e.g., Bradley et al., 2018) and adapts them specifically for spatio-temporal multivariate abundance data in community ecology. CBFMs are a (closely connected) alternative to the popular spatio-temporal latent variable models (LVMs) approach for joint species distribution modeling, as available in a number of packages such as \code{\link[Hmsc:Hmsc-package]{Hmsc::Hmsc-package()}} (Tikhonov et al., 2020), \code{\link[gllvm:gllvm]{gllvm::gllvm()}} (Niku et al., 2019), and \code{\link[boral:boral]{boral::boral()}} (Hui, 2016); see also Warton et al., (2015a,b), Thorson et al. (2016) and Ovaskainen and Abrego (2020) among others for general introductions to the use of LVMs in community ecology.  The key difference between LVMs and CBFMs is that rather than using a small number of latent variables (which are assumed to be random across observational units), CBFMs use a larger number of spatial and/or temporally-indexed basis functions that are specified \emph{a-priori} and remain fixed throughout the model fitting process (Hefley et al., 2017; Cressie et al., 2021). The randomness instead comes from species-specific regression coefficients related to these basis functions, which in turn induce spatio-temporal correlations within and between-species.

In using a basis function approach, CBFMs can thus be framed as a type of generalized additive model (GAM, Guisan et al., 2002; Wood, 2017) . This in turn means CBFMs can leverage from the plethora of techniques that have been already developed for GAMs, with one notable benefit being that computationally, CBFMs tend to more efficient and scale better than many existing implementations of spatio-temporal LVMs (at least, at the time of writing).
\subsection{Some mathematics}{

Turning to some mathematical details, the CBFM in this package is characterized by the following mean regression model. For observational unit \eqn{i=1,\ldots,N} (e.g., with a corresponding space-time coordinate) and species \eqn{j=1,\ldots,m}, we have

\deqn{g(\mu_{ij}) = \eta_{ij} = x_i^\top\beta_j + b_i^\top a_j,}

where \eqn{g(.)} is a known link function, \eqn{x_i} denotes a vector of predictors for unit \eqn{i} i.e., the \eqn{i}-th row from the created model matrix, \eqn{\beta_j} denotes the corresponding regression coefficients for species \eqn{j}, \eqn{b_i} denotes a vector of spatial and/or temporal basis functions for unit \eqn{i}, and \eqn{a_j} denotes the corresponding regression coefficients for species \eqn{j}.

The vector of predictors \eqn{x_i} is created based on the \code{formula} and \code{data} arguments. Smoothing terms are permitted in \code{formula}, and these can be included in the same way as in \code{\link[mgcv:gam.models]{mgcv::gam.models()}}; see also \code{\link[mgcv:smooth.terms]{mgcv::smooth.terms()}}. Note smoothing terms in this context also permits the inclusion of (species-specific) random intercepts and slopes, through the use of the \code{s(..., bs = "re")}; please see \code{\link[mgcv:random.effects]{mgcv::random.effects()}} and \code{\link[mgcv:gam.vcomp]{mgcv::gam.vcomp()}} for more details. These may be used, say, as a simple approach to account for nested sampling designs, multiple data sources/surveys etc..., although please note these random effects are specific to each species i.e., they are \emph{not} random row effects as found in packages such as \code{\link[boral:boral]{boral::boral()}} and \code{\link[gllvm:gllvm]{gllvm::gllvm()}}, and also are currently are not designed to draw the slopes from a common distribution as in \code{\link[Hmsc:Hmsc-package]{Hmsc::Hmsc-package()}} or Pollock et al., (2014), say.

When smoothing terms are included in the CBFM, a check of the smooth basis dimension and whether it is adequate is also automatically performed, courtesy of the \code{\link[mgcv:k.check]{mgcv::k.check()}} function; see that function's help file as well as \code{\link[mgcv:choose.k]{mgcv::choose.k()}} for more general details. Furthermore, selection of smoothing terms is also possible, using either shrinkage smoothers or null space penalization; please see \code{\link[mgcv:gam.selection]{mgcv::gam.selection()}} and \code{\link[mgcv:step.gam]{mgcv::step.gam()}} for more details. However, we warn the user that \strong{some of the smoothers available as part of \code{mgcv} e.g., \code{\link[mgcv:linear.functional.terms]{mgcv::linear.functional.terms()}}, has not been fully tested for CBFM}, so some make may not work. If you encounter any problems, please post a Github issue on the CBFM repository!

Next, the vector basis functions \eqn{b_i} is formed from the \code{B_space}, \code{B_time} and \code{B_spacetime} arguments. At least one of these arguments must be supplied. As an example, suppose we wish to fit a CBFM with spatial and temporal basis functions included in an additive manner. Then only \code{B_space} and \code{B_time} should be supplied, in which case the mean regression model for the CBFM can be written as:

\deqn{g(\mu_{ij}) = \eta_{ij} = x_i^\top\beta_j + b_{i,space}^\top a_{j,space} + b_{i,time}^\top a_{j,time},}

where \eqn{b_i = (b_{i,space}, b_{i,time})} and \eqn{a_j = (a_{j,space}, a_{j,time})}. If purely spatial or temporal multivariate abundance data is recorded, then one should only supply \code{B_space} and \code{B_time}, respectively, and the above mean regression model is simplified accordingly.

As another example, suppose we wish to include spatio-temporal basis functions (which are formed from a tensor-product). Then only \code{B_spacetime} should be supplied, in which case the mean regression model for the CBFM can be written as:

\deqn{g(\mu_{ij}) = \eta_{ij} = x_i^\top\beta_j + b_{i,spacetime}^\top a_{j,spacetime},}

where \eqn{b_i = b_{i,spacetime}} and \eqn{a_j = a_{j,spacetime}}. More details and recommendations on how to construct this basis functions, including the tensor-product mentioned above, are provided later on.

Note for zero-inflated distributions, it is the \emph{mean of the non-zero inflated component that is modeled and not the mean of the entire distribution.}

** Remark on flavors and choices of CBFMs:**
For spatio-temporal multivariate abundance data, we have found that the above two examples are usually the two most appropriate "flavors" CBFM to apply, although the precise form should of course depend upon the precise interpretation and question/s of interest. As seen above, we may want the separate sets of spatial and temporal basis functions to be included in an additive manner (this is analogous to an LVM where separate spatial LVs and temporal LVMs are added together), or have a single set of spatio-temporal basis functions formed from a tensor-product say (this is analogous to an LVM with one set of spatio-temporal LVs), or have a combination of the two where (say) the basis functions included in \code{B_space} and \code{B_time} are accounting for correlations on a coarse scale while the basis functions included in \code{B_spacetime} are accounting for resolutions on a fine scale. We refer the interested reader to Thorson et al., (2016) and Thorson (2019) for examples of similar kinds of constructs and flavors within the LVM framework.

In principle, it is possible to employ a more data-driven approach such as cross-validation or information criteria to choose which type of and/or the number of basis functions to include in the arguments \code{B_space/B_time/B_spacetime}. This similar to choosing the number of latent variables in a LVM. We refer the reader to \code{\link[mgcv:choose.k]{mgcv::choose.k()}} as some of the advice provided there may be applicable to CBFMs e.g., using residual analysis to informally check whether an increase the number of spatial and/or temporal basis functions is required, and echo a sentiment written there (while acknowledging things are more tricky with spatial and/or temporal basis functions, and for discrete responses!):

\emph{"So, exact choice of \eqn{k} (the number of basis functions in our situation) is not generally critical: it should be chosen to be large enough that you are reasonably sure of having enough degrees of freedom to represent the underlying 'truth' reasonably well, but small enough to maintain reasonable computational efficiency. Clearly 'large' and 'small' are dependent on the particular problem being addressed."}
}

\subsection{Basis function coefficients}{

In the CBFM, the basis functions \eqn{b_i} are specified \emph{a-priori} and remain fixed throughout the fitting process. Instead, it is the associated species-specific regression coefficients \eqn{a_j} which are assumed to be random. In this package, we assume follow a multivariate normal distribution as follows:

\deqn{(a_1,\ldots,a_m) \sim N(0, kronecker(G, \Sigma)),}

where \eqn{G} is a so-called baseline between-species correlation matrix, \eqn{\Sigma} is the community-level covariance matrix for the basis function regression coefficients, and \eqn{kronecker(\cdot)} is the Kronecker product operator. When multiple sets of basis functions are included, then this carries over. For instance, in the example above involving a CBFM with separate spatial and temporal basis functions, with only \code{B_space} and \code{B_time} supplied, we have

\deqn{(a_{1,space},\ldots,a_{m,space}) \sim N(0, kronecker(G_{space}, \Sigma_{space})),}
and
\deqn{(a_{1,time},\ldots,a_{m,time}) \sim N(0, kronecker(G_{time}, \Sigma_{time})).}

To reduce the number of parameters needed to be estimated in both the \eqn{G}'s and \eqn{\Sigma}'s, a rank-reduced form is by default adopted in both (inspired by the rank-reduced covariance matrices characterizing LVMs). In detail, we assume \eqn{G = \Lambda_{G}\Lambda_{G}^top + \kappa_G I_m} where \eqn{\Lambda_{G}} is an \eqn{m \times d_G} loading matrix and \eqn{\kappa_G > 0} is a nugget effect, with \eqn{I_m} being an identity matrix with dimension \eqn{m}. The quantity \eqn{d_G << m} is the rank, and similar to LVMs we often choose this to be small relative to the number of species. Similarly, we have \eqn{\Sigma = \Lambda_{\Sigma}\Lambda_{\Sigma}^top + \kappa_{\Sigma} I_{q}}, where \eqn{\Lambda_{\Sigma}} is an \eqn{q \times d_{\Sigma}} loading matrix, and \eqn{q} is the number of basis functions included in the model. When multiple sets of basis functions are included e.g., both \code{B_space} and \code{B_time}, then rank-reduced structures are used accordingly.

The ranks \eqn{d_G} and \eqn{d_{\Sigma}} are chosen generally to be smaller than the number of species and basis functions, respectively. Generally speaking, provided the rank/s is large enough, then results should not depend much on their choice. The nugget effect is included to ensure that resulting rank-reduced forms of \eqn{G} and \eqn{\Sigma} remain positive definite and generally a bit more stable. They can also have the interpretation of adjusting for the relative strength of correlation between species, say (Shirota, 2019).

It is also possible to assume full-rank covariance and correlation matrices for the \eqn{G}'s and \eqn{\Sigma}'s, via the character string "full" in \code{G_control$rank} and \code{Sigma_control$rank}. Other structures may gradually be implemented in future versions of the package.

It is also possible for the user to specific their own custom matrices for the community-level basis function covariance matrices \eqn{\Sigma} and/or the baseline between-species correlation matrices \eqn{G}. These are supplied through the \code{custom_space/custom_time/custom_spacetime} arguments as part of \code{Sigma_control} and \code{G_control}, respectively. In \eqn{\Sigma} is supplied, then only the corresponding \eqn{G} is estimated, and note importantly that the corresponding \eqn{G} is now estimated to be a baseline between-species \emph{covariance} matrix instead of correlation matrix (it is no longer constrained to be correlation matrix). Conversely, if \eqn{G} is supplied, then only the corresponding \eqn{\Sigma} is estimated. There is rarely any reason why one wish to supply both \eqn{\Sigma} and \eqn{G} simultaneously.

Using custom, pre-specified structures for \eqn{\Sigma} may be useful if the corresponding basis functions should be "equipped" with a particular structure. For example, if one or more sets of basis functions are constructed from, say, the \code{\link[mgcv:smooth.terms]{mgcv::smooth.terms()}} package (although see later on some defaults for constructing basis functions), then they are usually equipped with a corresponding, fixed penalty (inverse \eqn{\Sigma}) matrix. Perhaps a more common example is, say, if a user wanted to include species-specific random intercepts for time. Then one would set \code{B_time} as a model-matrix formed from treating time as a factor, and set \code{Sigma_control$custom_time} to an identity matrix with dimension equal to \code{ncol(B_time)}; see Example 3b in the help file below. After fitting, the estimated diagonal elements of \eqn{G_{time}} would then be the species-specific variance components for the time random intercept, while the off-diagonal elements may be interpreted as the corresponding between-species covariation.
}

\subsection{Distributions}{

The following response distributions are permitted:
\describe{
\item{\code{betalogitfam()}: }{Beta distribution using a logit link. The corresponding mean-variance relationship is given by \eqn{V = \mu(1-\mu)/(1+\phi)}, where \eqn{\mu} denotes the mean and \eqn{\phi} is the dispersion parameter.}
\item{\code{binomial(link = "logit")}: }{Binomial distribution using a logit link. The corresponding mean-variance relationship is given by \eqn{V = N_{trial}\mu(1-\mu)}, where \eqn{\mu} denotes the mean and \eqn{N_{trial}} is the trial size.}
\item{\code{Gamma(link = "log")}: }{Gamma distribution using a log link. The corresponding mean-variance relationship is given by \eqn{V = \phi\mu^2}, where \eqn{\mu} denotes the mean and \eqn{\phi} is the dispersion parameter.}
\item{\code{gaussian(link = "identity")}: }{Gaussian or normal distribution using an identity link. The corresponding mean-variance relationship is given by \eqn{V = \phi}, where \eqn{\phi} is the dispersion parameter.}
\item{\code{poisson(link = "log")}: }{Poisson distribution using a log link. The corresponding mean-variance relationship is given by \eqn{V = \mu}, where \eqn{\mu} denotes the mean.}
\item{\code{nb2()}: }{Negative binomial distribution with the log link. The corresponding mean-variance relationship is given by \eqn{V = \mu + \phi\mu^2}, where \eqn{\mu} denotes the mean and \eqn{\phi} is the dispersion parameter.}
\item{\code{tweedielogfam()}: }{Tweedie distribution using log link. The corresponding mean-variance relationship is given by \eqn{V = \phi\mu^{\rho}}, where \eqn{\mu} denotes the mean, \eqn{\phi} is the dispersion parameter, and \eqn{\rho} is the power parameter.}
\item{\code{zipoisson()}: }{Zero-inflated Poisson distribution using a log link for the Poisson part is permitted. This partial mass function of the distribution is given by \eqn{f(y) = \pi I(y=0) + (1-\pi) f_{pois}(y)}, where \eqn{\pi} is the probability of being in the zero-inflation component, while \eqn{f_{pois}(y)} is the usual Poisson distribution. The mean of the Poisson distribution is modeled against covariates and basis functions, while the probability of zero-inflation is also modeled against covariates via \code{ziformula}. In the case of the latter, a logit link function is used.}
\item{\code{zinb2()}: }{Zero-inflated negative binomial distribution using a log link for the negative binomial part is permitted. The partial mass function of the distribution is given by \eqn{f(y) = \pi I(y=0) + (1-\pi) f_{NB}(y)}, where \eqn{\pi} is the probability of being in the zero-inflation component, while \eqn{f_{NB}(y)} is the usual negative binomial distribution. The mean of the negative binomial distribution is modeled against covariates and basis functions, while the probability of zero-inflation is also modeled against covariates via \code{ziformula}. In the case of the latter, a logit link function is used.}
\item{\code{ztpoisson()}: }{Zero-truncated Poisson distribution using a log link. The partial mass function of the distribution is given by \eqn{f(y) = f_{pois}(y)/(1-f_{pois}(0)}) where \eqn{f_{pois}(y)} is the usual Poisson distribution as described above. The mean of the Poisson distribution is modeled against covariates and basis functions.}

\item{\code{ztnb2()}: }{Zero-truncated negative binomial distribution using a log link. The partial mass function of the distribution is given by \eqn{f(y) = f_{NB}(y)/(1-f_{NB}(0)}) where \eqn{f_{NB}(y)} is the usual negative binomial distribution as described above. The mean of the negative binomial distribution is modeled against covariates and basis functions.}

Hurdle CBFMs are also possible; please see \code{\link[=makeahurdle]{makeahurdle()}} for more information.
}

Missing (\code{NA}) values are permitted as part of the response matrix. These are simply passed over during the fitting process i.e., effectively the action \code{\link[stats:na.omit]{stats::na.omit()}} is taken.
}

\subsection{Constructing basis functions}{

The CBFM approach to spatio-temporal joint species distribution modeling relies on the inclusion of the \emph{pre-specified} spatial and/or temporal basis functions to account for spatio-temporal correlations within and between species (see Hefley et al., 2017, for a general overview of using basis functions to model autocorrelation in ecological data). Currently, the package does not provide default arguments to use for this, and this is deliberately as we wish to compel the user to work and think a bit harder on designing the right basis functions for use when CBFMs to their particular analysis.

At the same time, it would be remiss not to provide some brief recommendations based on previous experience, and we do so below. Please also see the examples later on for some more concrete applications.
\describe{
\item{\code{B_space}: }{We have found that the resolution adaptive thin-plate spline basis functions (Tzeng and Huang, 2018), as implemented in \code{\link[autoFRK:mrts]{autoFRK::mrts()}}, work fairly well here as spatial basis functions. They are simple to use and require the user to only supply the number of basis functions, which itself is tied to the resolution at which the user wants to model their spatial correlations. For spatial multivariate abundance data, we have usually found that 50 or less spatial basis functions of such type suffices.

Another option for spatial basis functions is to use \code{\link[FRK:auto_basis]{FRK::auto_basis()}}, which produces basis functions that are sparse in design but consequently require many more in number compared to the resolution adaptive thin-plate splines mentioned above. This approach is more customizable however, with the choice of resolutions, basis function centers, and aperture among other choices; please see Zammit-Mangion and Cressie (2017) and Wilke et al. (2019) for more details.}
\item{\code{B_time}: }{Both of the approaches mentioned above for \code{B_space} can also be applied here, although with temporal basis functions we have generally found the approach implemented in \code{\link[FRK:auto_basis]{FRK::auto_basis()}} to work satisfactorily in many cases, given their customizability and sparsity (local support). The resolution-adaptive thin-plate spline basis functions approach, when applied solely in the 1-D temporal dimension, can produce long-term temporal trends that may be undesirable.}
\item{\code{B_spacetime}: }{A general starting point for constructing spatio-temporal basis functions is to make use of a tensor-product form (analogous to \code{\link[mgcv:te]{mgcv::te()}}). That is, after constructing a set of spatial and a set of temporal basis functions, we can use the \code{\link[=tensorproduct]{tensorproduct()}} function to construct the tensor-product and include them \code{B_spacetime}.

It is recommended that both "ingredient" basis functions used in the tensor-product are sparse in design to facilitate computation e.g., as implemented in \code{\link[FRK:auto_basis]{FRK::auto_basis()}}; see the \code{FRK} package as well as Wilke et al. (2019) for some examples. Also, we recommend you do not use these same "ingredient" basis functions in the \code{B_space} and \code{B_time} arguments, as this may lead to overfitting. Put another way, and as hinted at previously, if \code{B_spacetime} is supplied at the same time as either \code{B_space} and/or \code{B_time} is supplied, then they should generally be constructed to model different resolutions/scales of the spatio-temporal correlation.}
}
}

\subsection{A note on estimation and inference}{

Because CBFMs uses a basis function approach to model spatio-temporal correlations between and within species, then they can be thought of as a type of GAM. Similar to a common implementation of GAMs then, this package uses a maximized penalized quasi-likelihood (PQL) approach for estimation and inference (Breslow and Clayton, 1993; Wood, 2017), while the baseline between-species correlation and community-level covariance matrices are by default estimated via Laplace approximated restricted maximum likelihood estimation (Wood, 2011; Wood, 2017). Currently, CBFM makes use of both the machinery available in the \link{mgcv} package (Wood, 2017) as well as that of Template Model Builder (TMB, Kristensen et al., 2016) to facilitate this entire algorithm. After the PQL algorithm has converged, a final estimation step is performed purely to update regression/basis function coefficients (and dispersion parameters if appropriate).

If \code{start_params} is not supplied, then CBFM attempts to obtain starting values based on fitting an appropriate stacked species distribution model. This generally works alright, but can sometimes fail badly e.g., if the stacked species distribution model severely overfits for one or more species. A tell-tale sign of when it occurs is if from the returned CBFM fit, the estimates of regression coefficients corresponding to the spatial and/or temporal basis functions i.e., \code{basis_effects_mat}, are extremely close to zero for these problematic species. There are not always easy fixes for such situations (as it may reflect an underlying, perhaps intriguing feature of the proposed model for the predictors, data, or it may genuinely be that the stacked species distribution model is already fitting incredibly well!). One \emph{ad-hoc} fix is available through \code{control$initial_betas_dampen}, but it is not guaranteed to work.

Standard errors and resulting inferential tools like confidence intervals are based on the approximate large sample distribution of the regression coefficients, and use the so-called Bayesian posterior covariance matrix for the coefficients, similar to (but not as sophisticated as!) what is provided  \code{\link[mgcv:summary.gam]{mgcv::summary.gam()}}. Please note that \strong{all standard errors and thus inference are currently computed without considering uncertainty in estimation of covariance \eqn{\Sigma} and correlation matrices \eqn{G}. They can lead to standard errors that are potentially too small, so please keep this in mind.}

Also, the current estimation approach \strong{does not provide uncertainty quantification of \eqn{\Sigma} and \eqn{G}}, does not provide uncertainty estimates in the smoothing parameter. This is in line with the main aims of this CBFM package, which are tailored more towards estimation and inference of regression coefficients and spatio-temporal prediction, in a relatively computationally efficient and scalable manner. Future versions of package may seek to rectify this, but for now... apologies!
}
}
\examples{
\donttest{
library(autoFRK)
library(FRK)
library(MASS)
library(mvabund)
library(mvtnorm)
library(ROCR)
library(sp)
library(RandomFields)
library(tidyverse)

##------------------------------
## **Example 1a: Fitting a CBFM to spatial multivariate presence-absence data**
## simulated from a spatial latent variable model
## Please note the data generation process (thus) differs from CBFM.
##------------------------------
set.seed(2021)
num_sites <- 1000 # 500 (units) sites for training set + 500 sites for testing.
num_spp <- 50 # Number of species
num_X <- 4 # Number of regression slopes

spp_slopes <- matrix(runif(num_spp * num_X, -1, 1), nrow = num_spp)
spp_intercepts <- runif(num_spp, -2, 0)

# Simulate spatial coordinates and environmental covariate components
# We will use this information in later examples as well
xy <- data.frame(x = runif(num_sites, 0, 5), y = runif(num_sites, 0, 5))
X <- rmvnorm(num_sites, mean = rep(0,4)) 
colnames(X) <- c("temp", "depth", "chla", "O2")
dat <- data.frame(xy, X)
mm <- model.matrix(~ temp + depth + chla + O2 - 1, data = dat) \%>\% 
scale \%>\% 
as.matrix

# Simulate latent variable component
# We will use this information in later examples as well
true_lvs <- RFsimulate(model = RMexp(var=1, scale=2), 
x = xy$x, y = xy$y, n = 2)@data \%>\% 
as.matrix
spp_loadings <- matrix(runif(num_spp * 2, -1, 1), nrow = num_spp) 
set.seed(NULL)

# Simulate spatial multivariate abundance data (presence-absence)
# We will use this information in later examples as well
eta <- tcrossprod(cbind(1,mm), cbind(spp_intercepts,spp_slopes)) + 
tcrossprod(true_lvs, spp_loadings)
simy <- matrix(rbinom(num_sites * num_spp, size = 1, 
prob = plogis(eta)), nrow = num_sites)

# Form training and test sets
dat_train <- dat[1:500,]
dat_test <- dat[501:1000,]
simy_train <- simy[1:500,]
simy_test <- simy[501:1000,]
rm(X, spp_loadings, true_lvs, xy, simy, dat)


# Fit stacked GLM as a baseline
fitstacked <- manyglm(simy_train ~ temp + depth + chla + O2, family = binomial(), data = dat_train)


# Set up spatial basis functions for CBFM -- Most users will start here! 
# We will also use this basis functions in some later examples
num_basisfunctions <- 25 # Number of spatial basis functions to use
# Training set basis functions
train_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
as.matrix \%>\%
{.[,-(1)]} # Remove the first intercept column
# Testing set basis functions
test_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
predict(newx = dat_test[,c("x","y")]) \%>\% 
as.matrix \%>\%
{.[,-c(1)]} 


# Fit CBFM 
tic <- proc.time()
useformula <- ~ temp + depth + chla + O2
fitcbfm <- CBFM(y = simy_train, formula = useformula, data = dat_train,,
B_space = train_basisfunctions, family = binomial(), control = list(trace = 1))
toc <- proc.time()
toc - tic

summary(fitcbfm) \%>\% 
str

# Example of plotting parametric model terms
fitcbfm$all_parametric_effects$species <- fitcbfm$all_parametric_effects$species \%>\%
fct_inorder
ggplot(fitcbfm$all_parametric_effects, aes(x = value, y = partial, color = species)) +
geom_line() +
geom_rug(aes(x = value), sides = "b", show.legend = FALSE, color = "black") +
facet_wrap(. ~ term, nrow = 2) +
labs(x = "Covariate", y = "Effect") +
theme_bw() +
theme(legend.position = "bottom")


# Calculate predictions onto test dataset
predictions_stacked <- predict(fitstacked, newdata = dat_test, type = "response")
predictions_cbfm <- predict(fitcbfm, newdata = dat_test, type = "response", 
new_B_space = test_basisfunctions)

# Evaluation predictions
# Tjur R-squared across species
tjurR2 <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
m1 <- predictions_stacked[which(simy_test[,j] > 0),j] \%>\%
mean(na.rm = TRUE)
m0 <- predictions_stacked[which(simy_test[,j] == 0),j] \%>\%
mean(na.rm = TRUE)
m1 - m0     
}),
cbfm = sapply(1:num_spp, function(j) { 
m1 <- predictions_cbfm[which(simy_test[,j] > 0),j] \%>\%
mean(na.rm = TRUE)
m0 <- predictions_cbfm[which(simy_test[,j] == 0),j] \%>\%
mean(na.rm = TRUE)
m1 - m0     
})
)

boxplot(tjurR2, main = "Tjur-R2", names = c("Stacked GLM", "CBFM"))

ggplot(tjurR2, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Tjur-R2") +
theme_bw()

# AUC across species
aucs <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
pred <- prediction(predictions_stacked[,j], labels = simy_test[,j]) \%>\%
performance(measure = "auc")  
pred@y.values[[1]]
}),
cbfm = sapply(1:num_spp, function(j) { 
pred <- prediction(predictions_cbfm[,j], labels = simy_test[,j]) \%>\%
performance(measure = "auc") 
pred@y.values[[1]]
})
)

boxplot(aucs, main = "AUC", names = c("Stacked GLM", "CBFM"))

ggplot(aucs, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "AUC") +
theme_bw()



##------------------------------
## **Example 1b: Repeat Example 1a but illustrate the use of smoothing terms in CBFM**
## Since the true model only involves parametric terms, then we do not expect its performance
## to be as good as assuming the right form for the mean model.
## It is purely for illustration purposes. 
## Please note this will take a while to run...get a cup of tea and stretch your legs! 
##------------------------------
# Set up spatial basis functions for CBFM -- Most users will start here! 
# This is the same set up as Example 1a
num_basisfunctions <- 25 # Number of spatial basis functions to use
# Training set basis functions
train_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
as.matrix \%>\%
{.[,-(1)]} # Remove the first intercept column
# Testing set basis functions
test_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
predict(newx = dat_test[,c("x","y")]) \%>\% 
as.matrix \%>\%
{.[,-c(1)]} 

# Fit CBFM 
tic <- proc.time()
useformula <- ~ temp + s(depth) + chla + s(O2)
fitcbfm_gam <- CBFM(y = simy_train, formula = useformula, 
data = dat_train, B_space = train_basisfunctions, family = binomial(), control = list(trace = 1))
toc <- proc.time()
toc-tic

summary(fitcbfm_gam) \%>\% 
str

# Example of plotting smooth model terms
fitcbfm_gam$all_smooth_estimates$species <- fitcbfm_gam$all_smooth_estimates$species \%>\%
fct_inorder
ggplot() +
geom_line(data = fitcbfm_gam$all_smooth_estimates \%>\% subset(smooth == "s(depth)"), 
aes(x = depth, y = est, color = species), show.legend = FALSE) +
geom_rug(aes(x = depth), data = dat_train, sides = "b", color = "black") +
labs(x = "depth", y = "Effect") +
theme_bw()


# Calculate predictions onto test dataset
predictions_cbfm_gam <- predict(fitcbfm_gam, newdata = dat_test, type = "response", 
new_B_space = test_basisfunctions)

# Evaluation predictions
# Tjur R-squared across species
tjurR2$cbfm_gam = sapply(1:num_spp, function(j) { 
m1 <- predictions_cbfm_gam[which(simy_test[,j] > 0),j] \%>\%
mean(na.rm = TRUE)
m0 <- predictions_cbfm_gam[which(simy_test[,j] == 0),j] \%>\%
mean(na.rm = TRUE)
m1 - m0     
})

boxplot(tjurR2, main = "Tjur-R2", names = c("Stacked GLM", "CBFM", "CBFM (GAM)"))

ggplot(tjurR2, aes(x = stacked, y = cbfm_gam)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM (GAM)", main = "Tjur-R2") +
theme_bw()

# AUC across species
aucs$cbfm_gam <- sapply(1:num_spp, function(j) { 
pred <- prediction(predictions_cbfm_gam[,j], labels = simy_test[,j]) \%>\%
performance(measure = "auc") 
pred@y.values[[1]]
})

boxplot(aucs, main = "AUC", names = c("Stacked GLM", "CBFM", "CBFM (GAM)"))

ggplot(aucs, aes(x = stacked, y = cbfm_gam)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM (GAM)", main = "AUC") +
theme_bw()



##------------------------------
## **Example 1c: Repeat Example 1a but illustrate applications to Poisson count data**
##------------------------------
# Simulate spatial multivariate abundance data
simy <- matrix(rpois(num_sites * num_spp, lambda = exp(eta)), nrow = num_sites)

# Form training and test sets
simy_train <- simy[1:500,]
simy_test <- simy[501:1000,]


# Fit stacked GLM as a baseline
fitstacked <- manyglm(simy_train ~ temp + depth + chla + O2, family = "poisson", 
data = dat_train)


# Set up spatial basis functions for CBFM -- Most users will start here! 
# This is the same set up as examples above
num_basisfunctions <- 25 # Number of spatial basis functions to use
# Training set basis functions
train_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
as.matrix \%>\%
{.[,-(1)]} # Remove the first intercept column
# Testing set basis functions
test_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
predict(newx = dat_test[,c("x","y")]) \%>\% 
as.matrix \%>\%
{.[,-c(1)]} 

# Fit Poisson CBFM 
tic <- proc.time()
useformula <- ~ temp + depth + chla + O2
fitcbfm <- CBFM(y = simy_train, formula = useformula, data = dat_train, 
B_space = train_basisfunctions, family = poisson(), control = list(trace = 1))
toc <- proc.time()
toc - tic

summary(fitcbfm) \%>\% 
str


# Calculate predictions onto test dataset
predictions_stacked <- predict(fitstacked, newdata = dat_test, type = "response")
predictions_cbfm <- predict(fitcbfm, newdata = dat_test, type = "response", 
new_B_space = test_basisfunctions)

# Evaluation predictions
# Pseudo R-squared across species
pseudoR2 <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
out <- cor(predictions_stacked[,j], simy_test[,j], method = "spearman")
out^2 * sign(out)     
}),
cbfm = sapply(1:num_spp, function(j) { 
out <- cor(predictions_cbfm[,j], simy_test[,j], method = "spearman")
out^2 * sign(out)     
})
)

boxplot(pseudoR2, main = "Pseudo-R2", names = c("Stacked GLM", "CBFM"))

ggplot(pseudoR2, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Pseudo-R2") +
theme_bw()

# Predictive deviance across species (lower is better)
preddeviance <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
-2*sum(dpois(simy_test[,j], lambda = predictions_stacked[,j], log = TRUE))
}),
cbfm = sapply(1:num_spp, function(j) { 
-2*sum(dpois(simy_test[,j], lambda = predictions_cbfm[,j], log = TRUE))
})
)

boxplot(preddeviance, main = "Deviance", names = c("Stacked GLM", "CBFM"))

ggplot(preddeviance, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Deviance") +
theme_bw()


##------------------------------
## **Example 1d: Repeat Example 1a but illustrate applications to negative binomial count data** 
##------------------------------
# Simulate spatial multivariate abundance data
spp_dispersion <- runif(num_spp)
simy <- matrix(rnbinom(num_sites * num_spp, mu = exp(eta), 
size = matrix(1/spp_dispersion, nrow = num_sites, ncol = num_spp, byrow = TRUE)),
nrow = num_sites)

# Form training and test sets
simy_train <- simy[1:500,]
simy_test <- simy[501:1000,]

# Fit stacked GLM as a baseline
fitstacked <- manyglm(simy_train ~ temp + depth + chla + O2, family = "negative.binomial",
data = dat_train)


# Set up spatial basis functions for CBFM -- Most users will start here! 
# This is the same set up as examples above
num_basisfunctions <- 25 # Number of spatial basis functions to use
# Training set basis functions
train_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
as.matrix \%>\%
{.[,-(1)]} # Remove the first intercept column
# Testing set basis functions
test_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
predict(newx = dat_test[,c("x","y")]) \%>\% 
as.matrix \%>\%
{.[,-c(1)]} 

# Fit negative binomial CBFM
# Please make sure you set up spatial basis functions for CBFM, we do so in Example 1a
# Please note the negative binomial distribution is not necessarily required for 
# overdispersed count data, since the latent variables can to some degree account for
# overdispersion. 
tic <- proc.time()
useformula <- ~ temp + depth + chla + O2
fitcbfm <- CBFM(y = simy_train, formula = useformula, data = dat_train, 
B_space = train_basisfunctions, family = nb2(), control = list(trace = 1))
toc <- proc.time()
toc - tic

summary(fitcbfm) \%>\% 
str


# Calculate predictions onto test dataset
predictions_stacked <- predict(fitstacked, newdata = dat_test, type = "response")
predictions_cbfm <- predict(fitcbfm, newdata = dat_test, type = "response", 
new_B_space = test_basisfunctions)

# Evaluation predictions
# Pseudo R-squared across species
pseudoR2 <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
out <- cor(predictions_stacked[,j], simy_test[,j], method = "spearman")
out^2 * sign(out)     
}),
cbfm = sapply(1:num_spp, function(j) { 
out <- cor(predictions_cbfm[,j], simy_test[,j], method = "spearman")
out^2 * sign(out)     
})
)

boxplot(pseudoR2, main = "Pseudo-R2", names = c("Stacked GLM", "CBFM"))

ggplot(pseudoR2, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Pseudo-R2") +
theme_bw()

# Predictive deviance across species (lower is better)
preddeviance <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
-2*sum(dnbinom(simy_test[,j], mu = predictions_stacked[,j], size = 1/fitstacked$phi[j], 
log = TRUE))
}),
cbfm = sapply(1:num_spp, function(j) { 
-2*sum(dnbinom(simy_test[,j], mu = predictions_cbfm[,j], size = 1/fitcbfm$dispparam[j], 
log = TRUE))
})
)

boxplot(preddeviance, main = "Deviance", names = c("Stacked GLM", "CBFM"))

ggplot(preddeviance, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Deviance") +
theme_bw()


##------------------------------
## **Example 1e: Repeat Example 1a but illustrate applications to ZIP count data** 
##------------------------------
library(gamlss)
library(pscl)

# Probability of zero-inflation 
spp_zislopes <- matrix(runif(num_spp * num_X, -1, 1), nrow = num_spp)
spp_ziintercepts <- runif(num_spp, -0.5, 0)

# Simulate spatial multivariate abundance data
# Note the deliberate "+2" on the linear predictor: This creates data that is a bit more 
# clearly overdispersed and zero-inflated...
zieta <- tcrossprod(cbind(1,mm), cbind(spp_ziintercepts,spp_zislopes))
component_ind <- matrix(rbinom(num_sites * num_spp, size = 1, 
prob = matrix(plogis(zieta), num_sites, num_spp, byrow = TRUE)), num_sites,num_spp)
simy <- matrix(rpois(num_sites * num_spp, lambda = exp(eta+2) * (1-component_ind)), 
num_sites, num_spp)
rm(component_ind, zieta)

# Form training and test sets
simy_train <- simy[1:500,]
simy_test <- simy[501:1000,]


# Fit stacked zero-inflated Poisson regression models as a baseline
fitstacked <- NULL 
for(j in 1:num_spp) {
fitstacked[[j]] <- zeroinfl(resp ~ temp + depth + chla + O2, 
data = data.frame(resp = simy_train[,j], dat_train))
}


# Set up spatial basis functions for CBFM -- Most users will start here! 
# This is the same set up as examples above
num_basisfunctions <- 25 # Number of spatial basis functions to use
# Training set basis functions
train_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
as.matrix \%>\%
{.[,-(1)]} # Remove the first intercept column
# Testing set basis functions
test_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
predict(newx = dat_test[,c("x","y")]) \%>\% 
as.matrix \%>\%
{.[,-c(1)]} 


# Fit zero-inflated Poisson CBFM
tic <- proc.time()
useformula <- ~ temp + depth + chla + O2
fitcbfm <- CBFM(y = simy_train, formula = useformula, ziformula = useformula, data = dat_train, 
B_space = train_basisfunctions, family = zipoisson(), control = list(trace = 1))
toc <- proc.time()
toc - tic

summary(fitcbfm) \%>\% 
str


# Calculate predictions onto test dataset
predictions_stacked <- sapply(1:num_spp, function(j) predict(fitstacked[[j]], 
newdata = dat_test, type = "response"))
predictions_cbfm <- exp(predict(fitcbfm, newdata = dat_test, type = "response", 
new_B_space = test_basisfunctions))

# Evaluation predictions
# Pseudo R-squared across species
pseudoR2 <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
out <- cor(predictions_stacked[,j], simy_test[,j], method = "spearman")
out^2 * sign(out)     
}),
cbfm = sapply(1:num_spp, function(j) { 
out <- cor(predictions_cbfm[,j], simy_test[,j], method = "spearman")
out^2 * sign(out)     
})
)

boxplot(pseudoR2, main = "Pseudo-R2", names = c("Stacked GLM", "CBFM"))

ggplot(pseudoR2, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Pseudo-R2") +
theme_bw()

# Predictive deviance across species (lower is better)
countpredictions_stacked <- sapply(1:num_spp, function(j) predict(fitstacked[[j]], 
newdata = dat_test, type = "count"))
zipredictions_stacked <- sapply(1:num_spp, function(j) predict(fitstacked[[j]], 
newdata = dat_test, type = "zero"))
countpredictions_cbfm <- exp(predict(fitcbfm, newdata = dat_test, type = "link", 
new_B_space = test_basisfunctions))
zipredictions_cbfm <- plogis(tcrossprod(
predict(fitcbfm, newdata = dat_test, type = "zilpmatrix"), fitcbfm$zibetas))

preddeviance <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
-2*sum(dZIP(simy_test[,j], mu = countpredictions_stacked[,j], 
sigma = zipredictions_stacked[,j], log = TRUE))
}),
cbfm = sapply(1:num_spp, function(j) { 
-2*sum(dZIP(simy_test[,j], mu = countpredictions_cbfm[,j], 
sigma = zipredictions_cbfm[,j], log = TRUE))
})
)

boxplot(preddeviance, main = "Deviance", names = c("Stacked GLM", "CBFM"))

ggplot(preddeviance, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Deviance") +
theme_bw()

rm(countpredictions_stacked, zipredictions_stacked, 
countpredictions_cbfm, zipredictions_cbfm)


##------------------------------
## **Example 1f: Repeat Example 1a but illustrate applications to ZINB count data**
## **This time, we use constant species-specific probabilities of zero inflation**
##------------------------------
# Probability of zero-inflation 
spp_zeroinfl_prob <- runif(num_spp, 0.1, 0.5) 
spp_dispersion <- runif(num_spp)

# Simulate spatial multivariate abundance data
# Note the deliberate "+2" on the linear predictor: This creates data that is a bit more 
# clearly overdispersed and zero-inflated...
component_ind <- matrix(rbinom(num_sites * num_spp, size = 1, 
prob = matrix(spp_zeroinfl_prob, num_sites, num_spp, byrow = TRUE)), num_sites, num_spp)
simy <- matrix(rnbinom(num_sites * num_spp, mu = exp(eta+2) * (1-component_ind),
size = matrix(1/spp_dispersion, nrow = num_sites, ncol = num_spp, byrow = TRUE)),
num_sites, num_spp)
rm(component_ind)

# Form training and test sets
simy_train <- simy[1:500,]
simy_test <- simy[501:1000,]


# Fit stacked zero-inflated NB regression models as a baseline
fitstacked <- NULL 
for(j in 1:num_spp) {
fitstacked[[j]] <- zeroinfl(resp ~ temp + depth + chla + O2 | 1, 
dist = "negbin", data = data.frame(resp = simy_train[,j], dat_train))
}


# Set up spatial basis functions for CBFM -- Most users will start here! 
# This is the same set up as examples above
num_basisfunctions <- 25 # Number of spatial basis functions to use
# Training set basis functions
train_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
as.matrix \%>\%
{.[,-(1)]} # Remove the first intercept column
# Testing set basis functions
test_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
predict(newx = dat_test[,c("x","y")]) \%>\% 
as.matrix \%>\%
{.[,-c(1)]} 

# Fit zero-inflated negative binomial CBFM
tic <- proc.time()
useformula <- ~ temp + depth + chla + O2
fitcbfm <- CBFM(y = simy_train, formula = useformula, ziformula = ~ 1, data = dat_train, 
B_space = train_basisfunctions, family = zinb2(), control = list(trace = 1))
toc <- proc.time()
toc - tic

summary(fitcbfm) \%>\% 
str


# Calculate predictions onto test dataset
predictions_stacked <- sapply(1:num_spp, function(j) predict(fitstacked[[j]], 
newdata = dat_test, type = "response"))
predictions_cbfm <- predict(fitcbfm, newdata = dat_test, type = "response", 
new_B_space = test_basisfunctions)

# Evaluation predictions
# Pseudo R-squared across species
pseudoR2 <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
out <- cor(predictions_stacked[,j], simy_test[,j], method = "spearman")
out^2 * sign(out)     
}),
cbfm = sapply(1:num_spp, function(j) { 
out <- cor(predictions_cbfm[,j], simy_test[,j], method = "spearman")
out^2 * sign(out)     
})
)

boxplot(pseudoR2, main = "Pseudo-R2", names = c("Stacked GLM", "CBFM"))

ggplot(pseudoR2, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Pseudo-R2") +
theme_bw()

# Predictive deviance across species (lower is better)
countpredictions_stacked <- sapply(1:num_spp, function(j) predict(fitstacked[[j]], 
newdata = dat_test, type = "count"))
zipredictions_stacked <- sapply(1:num_spp, function(j) predict(fitstacked[[j]], 
newdata = dat_test, type = "zero"))
countpredictions_cbfm <- exp(predict(fitcbfm, newdata = dat_test, type = "link", 
new_B_space = test_basisfunctions))
zipredictions_cbfm <- plogis(tcrossprod(
predict(fitcbfm, newdata = dat_test, type = "zilpmatrix"), fitcbfm$zibetas))

preddeviance <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
-2*sum(dZINBI(simy_test[,j], mu = countpredictions_stacked[,j], 
nu = zipredictions_stacked[,j], sigma = 1/fitstacked[[j]]$theta), log = TRUE)
}),
cbfm = sapply(1:num_spp, function(j) { 
-2*sum(dZINBI(simy_test[,j], mu = countpredictions_cbfm[,j], 
nu = zipredictions_cbfm[,j], sigma = fitcbfm$dispparam[j]), log = TRUE)
})
)

boxplot(preddeviance, main = "Deviance", names = c("Stacked GLM", "CBFM"))

ggplot(preddeviance, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Deviance") +
theme_bw()



##------------------------------
## **Example 1g Repeat Example 1a but illustrate applications to biomass**
##------------------------------
library(tweedie)
library(statmod)

spp_dispersion <- runif(num_spp, 0, 5)
simy <- matrix(rtweedie(num_sites * num_spp, mu = exp(eta), 
phi = matrix(spp_dispersion, nrow = num_sites, ncol = num_spp, byrow = TRUE),
power = 1.6),
nrow = num_sites)

# Form training and test sets
simy_train <- simy[1:500,]
simy_test <- simy[501:1000,]

# Fit stacked GLM as a baseline
fitstacked <- lapply(1:num_spp, function(j) {
# Note power parameter is assumed to be known for stacked model
glm(simy_train[,j] ~ temp + depth + chla + O2, 
family = tweedie(var.power = 1.6, link.power = 0), data = dat_train)
})


# Set up spatial basis functions for CBFM -- Most users will start here! 
# This is the same set up as examples above
num_basisfunctions <- 25 # Number of spatial basis functions to use
# Training set basis functions
train_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
as.matrix \%>\%
{.[,-(1)]} # Remove the first intercept column
# Testing set basis functions
test_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
predict(newx = dat_test[,c("x","y")]) \%>\% 
as.matrix \%>\%
{.[,-c(1)]} 

# Fit Tweedie CBFM
tic <- proc.time()
useformula <- ~ temp + depth + chla + O2
fitcbfm <- CBFM(y = simy_train, formula = useformula, data = dat_train, 
B_space = train_basisfunctions, family = tweedielogfam(), control = list(trace = 1))
toc <- proc.time()
toc - tic

summary(fitcbfm) \%>\% 
str


# Calculate predictions onto test dataset
predictions_stacked <- sapply(1:num_spp, function(j) {
predict(fitstacked[[j]], newdata = dat_test, type = "response")
})
predictions_cbfm <- predict(fitcbfm, newdata = dat_test, type = "response", 
new_B_space = test_basisfunctions)

# Evaluation predictions
# Pseudo R-squared across species
pseudoR2 <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
out <- cor(predictions_stacked[,j], simy_test[,j], method = "spearman")
out^2 * sign(out)     
}),
cbfm = sapply(1:num_spp, function(j) { 
out <- cor(predictions_cbfm[,j], simy_test[,j], method = "spearman")
out^2 * sign(out)     
})
)

boxplot(pseudoR2, main = "Pseudo-R2", names = c("Stacked GLM", "CBFM"))

ggplot(pseudoR2, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Pseudo-R2") +
theme_bw()

# Predictive deviance across species (lower is better)
preddeviance <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
-2*sum(log(dtweedie(simy_test[,j], mu = predictions_stacked[,j], 
phi = mean(fitstacked[[j]]$residuals^2), power = 1.6)))
}),
cbfm = sapply(1:num_spp, function(j) { 
-2*sum(log(dtweedie(simy_test[,j], mu = predictions_cbfm[,j], 
phi = fitcbfm$dispparam[j], power = fitcbfm$powerparam[j])))
})
)

boxplot(preddeviance, main = "Deviance", names = c("Stacked GLM", "CBFM"))

ggplot(preddeviance, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Deviance") +
theme_bw()

rm(list = ls())



##------------------------------
## **Example 1h: Repeat Example 1a but illustrate applications to zero-truncated count data** 
## This one could take a while...grab a cuppa while you wait!
##------------------------------
library(gamlss)
library(gamlss.tr)
gen.trun(0, family = "NBI")

set.seed(2021)
num_sites <- 1000 # 500 (units) sites for training set + 500 sites for testing.
num_spp <- 50 # Number of species
num_X <- 4 # Number of regression slope
spp_slopes <- matrix(runif(num_spp * num_X, -1, 1), nrow = num_spp)
spp_intercepts <- runif(num_spp, -2, 0)

# Simulate spatial coordinates and environmental covariate components
# We will use this information in later examples as well
xy <- data.frame(x = runif(num_sites, 0, 5), y = runif(num_sites, 0, 5))
X <- rmvnorm(num_sites, mean = rep(0,4)) 
colnames(X) <- c("temp", "depth", "chla", "O2")
dat <- data.frame(xy, X)

# Simulate latent variable component
# We will use this information in later examples as well
true_lvs <- RFsimulate(model = RMexp(var=1, scale=2), 
x = xy$x, y = xy$y, n = 2)@data \%>\% 
as.matrix
spp_loadings <- matrix(runif(num_spp * 2, -1, 1), nrow = num_spp) 
set.seed(NULL)

# Simulate spatial multivariate abundance data (presence-absence)
# We will use this information in later examples as well
eta <- tcrossprod(cbind(1,mm), cbind(spp_intercepts,spp_slopes)) + 
tcrossprod(true_lvs, spp_loadings)

spp_dispersion <- runif(num_spp)
# Simulate spatial multivariate abundance data
simy <- matrix(rNBItr(num_sites * num_spp, mu = exp(eta), sigma = 
matrix(spp_dispersion, num_sites, num_spp, byrow = TRUE)), num_sites, num_spp)

# Form training and test sets
dat_train <- dat[1:500,]
dat_test <- dat[501:1000,]
simy_train <- simy[1:500,]
simy_test <- simy[501:1000,]


# Fit stacked zero-truncated regression models as a baseline
# Note gamlss may sometimes fail...
fitstacked <- NULL 
for(j in 1:num_spp) {
fitstacked[[j]] <- gamlss(resp ~ temp + depth + chla + O2, 
data = data.frame(resp = simy_train[,j], dat_train), family = NBItr)
}


# Set up spatial basis functions for CBFM -- Most users will start here! 
# This is the same set up as examples above
num_basisfunctions <- 25 # Number of spatial basis functions to use
# Training set basis functions
train_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
as.matrix \%>\%
{.[,-(1)]} # Remove the first intercept column
# Testing set basis functions
test_basisfunctions <- mrts(dat_train[,c("x","y")], num_basisfunctions) \%>\% 
predict(newx = dat_test[,c("x","y")]) \%>\% 
as.matrix \%>\%
{.[,-c(1)]} 

# Fit zero-truncated negative binomial CBFM
tic <- proc.time()
useformula <- ~ temp + depth + chla + O2
fitcbfm <- CBFM(y = simy_train, formula = useformula, data = dat_train, 
B_space = train_basisfunctions, family = ztnb2(), control = list(trace = 1))
toc <- proc.time()
toc - tic

summary(fitcbfm) \%>\% 
str


# Calculate predictions onto test dataset
# Note extra step needed for stacked models from gamlss to get the actual fitted values 
predictions_stacked <- sapply(1:num_spp, function(j) predict(fitstacked[[j]], 
newdata = dat_test, type = "response"))
stacked_dispparam <- sapply(1:num_spp, function(j) exp(fitstacked[[j]]$sigma.coefficient))
stacked_dispparam <- matrix(stacked_dispparam, nrow(dat_test), num_spp, byrow = TRUE)
predictions_stacked <- predictions_stacked / 
(1-dnbinom(0, mu = predictions_stacked, size = 1/stacked_dispparam))
predictions_cbfm <- predict(fitcbfm, newdata = dat_test, type = "response", 
new_B_space = test_basisfunctions)

# Evaluation predictions
# Pseudo R-squared across species
pseudoR2 <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
out <- cor(predictions_stacked[,j], simy_test[,j], method = "spearman")
out^2 * sign(out)     
}),
cbfm = sapply(1:num_spp, function(j) { 
out <- cor(predictions_cbfm[,j], simy_test[,j], method = "spearman")
out^2 * sign(out)     
})
)

boxplot(pseudoR2, main = "Pseudo-R2", names = c("Stacked GLM", "CBFM"))

ggplot(pseudoR2, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Pseudo-R2") +
theme_bw()

# Predictive deviance across species (lower is better)
# Need to define density of zero-inflated NB distribution first (or get it from a package)
preddeviance <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
-2*sum(dNBItr(simy_test[,j], mu = predictions_stacked[,j], 
sigma = exp(fitstacked[[j]]$sigma.coefficient), log = TRUE))
}),
cbfm = sapply(1:num_spp, function(j) { 
-2*sum(dNBItr(simy_test[,j], mu = predictions_cbfm[,j], 
sigma = fitcbfm$dispparam[j], log = TRUE))
})
)

boxplot(preddeviance, main = "Deviance", names = c("Stacked GLM", "CBFM"))

ggplot(preddeviance, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM", main = "Deviance") +
theme_bw()


## Please see the makeahurdle function for uses of the above for hurdle count models



##------------------------------
## **Example 2a: Fitting a CBFM to multivariate spatial continuous data**
## with a data generation pulled from the Hmsc vignette (also spatial latent variable model)
## Please see Case 6 in
## <https://cran.r-project.org/web/packages/Hmsc/vignettes/vignette_5_performance.pdf>
##------------------------------
library(Hmsc)
library(devtools)

# The makedata function included in the vignette folder produces datasets 
# based on the Hmsc model
source_url("https://raw.githubusercontent.com/hmsc-r/HMSC/master/vignettes/makedata.R")

tmp = makedata(ns=50, ny=200, spatial=TRUE)
all.data=tmp[[1]]
all.parameters=tmp[[2]]

# Fit stacked GLM as a baseline
fitstacked <- manylm(all.data$Y ~ X.categorical + X.covariate, data = all.data$X.data)


# Set up spatial basis functions for CBFM -- Most users will start here! 
num_basisfunctions <- 20 # Number of spatial basis functions to use
basisfunctions <- mrts(all.data$xy, num_basisfunctions) \%>\% 
as.matrix \%>\%
{.[,-(1)]} # Remove the first intercept column

# Fit CBFM 
tic <- proc.time()
fitcbfm <- CBFM(y = all.data$Y, formula = all.data$X.formula, data = all.data$X.data, 
B_space = basisfunctions, family = gaussian(), control = list(trace = 1))
toc <- proc.time()
toc - tic

summary(fitcbfm) \%>\% 
str


# Evaluate in-sample performance (similar to what was done in the Hmsc vignette)
# with the evaluateModelFit() function 
predictions_stacked <- fitstacked$fitted
predictions_cbfm <- fitcbfm$fitted 

num_spp <- ncol(all.data$Y)

# Root mean-squared error (RMSE)
RMSE <- data.frame(stacked = sapply(1:num_spp, function(j) {
sqrt(mean((all.data$Y[,j]-predictions_stacked[,j])^2))
}),
cbfm = sapply(1:num_spp, function(j) {
sqrt(mean((all.data$Y[,j]-predictions_cbfm[,j])^2))
})
)
boxplot(RMSE, main = "RMSE", names = c("Stacked GLM", "CBFM"))

pearsonR2 <- data.frame(stacked = sapply(1:num_spp, function(j) {
out <- cor(all.data$Y[,j], predictions_stacked[,j])
out^2 * sign(out)
}),
cbfm = sapply(1:num_spp, function(j) {
out <- cor(all.data$Y[,j],predictions_cbfm[,j])
out^2 * sign(out)
})
)
boxplot(pearsonR2, main = "Pearson R-squared", names = c("Stacked GLM", "CBFM"))

pearsonR2 <- data.frame(stacked = sapply(1:num_spp, function(j) {
out <- cor(all.data$Y[,j], predictions_stacked[,j])
out^2 * sign(out)
}),
cbfm = sapply(1:num_spp, function(j) {
out <- cor(all.data$Y[,j],predictions_cbfm[,j])
out^2 * sign(out)
})
)
boxplot(pearsonR2, main = "Pearson R-squared", names = c("Stacked GLM", "CBFM"))



##------------------------------
## **Example 2b: Repeat example 2a with presence-absence data**
## Similar to a combination of Cases 2 and 6 in
## <https://cran.r-project.org/web/packages/Hmsc/vignettes/vignette_5_performance.pdf>
##------------------------------
# Generate data
L1 = all.parameters$L
Y2 = 1*(L1 + matrix(rnorm(n = nrow(all.data$Y)*ncol(all.data$Y)), ncol = ncol(all.data$Y)) > 0)
all.data$Y = Y2


# Fit stacked GLM as a baseline
fitstacked <- manyglm(all.data$Y ~ X.categorical + X.covariate, data = all.data$X.data,
family = binomial())


# Set up spatial basis functions for CBFM -- Most users will start here! 
num_basisfunctions <- 20 # Number of spatial basis functions to use
basisfunctions <- mrts(all.data$xy, num_basisfunctions) \%>\% 
as.matrix \%>\%
{.[,-(1)]} # Remove the first intercept column

# Fit CBFM 
# Note also that Hmsc generates and fits models assuming a probit link, 
# but CBFM uses a logit link
tic <- proc.time()
fitcbfm <- CBFM(y = all.data$Y, formula = all.data$X.formula, data = all.data$X.data, 
B_space = basisfunctions, family = binomial(), control = list(trace = 1))
toc <- proc.time()
toc - tic


# Evaluate in-sample performance (similar to what was done in the Hmsc vignette)
# with the evaluateModelFit() function 
predictions_stacked <- fitstacked$fitted
predictions_cbfm <- fitcbfm$fitted 

num_spp <- ncol(all.data$Y)

# Root mean-squared error (RMSE)
RMSE <- data.frame(stacked = sapply(1:num_spp, function(j) {
sqrt(mean((all.data$Y[,j]-predictions_stacked[,j])^2))
}),
cbfm = sapply(1:num_spp, function(j) {
sqrt(mean((all.data$Y[,j]-predictions_cbfm[,j])^2))
})
)
boxplot(RMSE, main = "RMSE", names = c("Stacked GLM", "CBFM"))

# Tjur R-squared across species
tjurR2 <- data.frame(stacked = sapply(1:num_spp, function(j) { 
m1 <- predictions_stacked[which(all.data$Y[,j] > 0),j] \%>\%
mean(na.rm = TRUE)
m0 <- predictions_stacked[which(all.data$Y[,j] == 0),j] \%>\%
mean(na.rm = TRUE)
m1 - m0     
}),
cbfm = sapply(1:num_spp, function(j) { 
m1 <- predictions_cbfm[which(all.data$Y[,j] > 0),j] \%>\%
mean(na.rm = TRUE)
m0 <- predictions_cbfm[which(all.data$Y[,j] == 0),j] \%>\%
mean(na.rm = TRUE)
m1 - m0     
})
)
boxplot(tjurR2, main = "Tjur-R2", names = c("Stacked GLM", "CBFM"))

# AUC across species
aucs <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
pred <- prediction(predictions_stacked[,j], labels = all.data$Y[,j]) \%>\%
performance(measure = "auc")  
pred@y.values[[1]]
}),
cbfm = sapply(1:num_spp, function(j) { 
pred <- prediction(predictions_cbfm[,j], labels = all.data$Y[,j]) \%>\%
performance(measure = "auc") 
pred@y.values[[1]]
})
)
boxplot(aucs, main = "AUC", names = c("Stacked GLM", "CBFM"))

set.seed(NULL)
rm(list = ls())



##------------------------------
## **Example 3a: Fitting an additive CBFM to spatio-temporal multivariate presence-absence data**
## Simulated from a spatio-temporal latent variable model
## Please note the data generation process (thus) differs from CBFM.
## The additive CBFM might take a while to fit...grab a cuppa!
##------------------------------
set.seed(2021)
num_sites <- 1000 # 500 (units) sites for training set + 500 sites for testing.
num_spp <- 50 # Number of species
num_X <- 4 # Number of regression slopes

spp_slopes <- matrix(runif(num_spp * num_X, -1, 1), nrow = num_spp)
spp_intercepts <- runif(num_spp, -2, 0)

# Simulate spatio-temporal coordinates and environmental covariate components
# Note we assume that each site is only visited once, but the code below can be adapted to 
# when the same sites are repeatedly visited
# We will also use this information in examples below
xy <- data.frame(x = runif(num_sites, 0, 5), y = runif(num_sites, 0, 5))
X <- rmvnorm(num_sites, mean = rep(0,4)) 
colnames(X) <- c("temp", "depth", "chla", "O2")
dat <- data.frame(xy, time = sort(runif(1000, 0, 10)) , X)
mm <- model.matrix(~ temp + depth + chla + O2 - 1, data = dat) \%>\% 
scale \%>\% 
as.matrix

# Simulate latent variable component
# We will also use this information in examples below
true_space_lvs <- RFsimulate(model = RMexp(var = 1, scale = 2), x = xy$x, y = xy$y, 
n = 2)@data \%>\% 
as.matrix
true_time_lvs <- RFsimulate(model = RMgauss(var = 1, scale = 1), x = dat$time, 
n = 2)@data \%>\% 
as.matrix
spp_space_loadings <- matrix(runif(num_spp * 2, -1, 1), nrow = num_spp) 
spp_time_loadings <- matrix(runif(num_spp * 2, -0.5, 0.5), nrow = num_spp) 

# Simulate spatial multivariate abundance data (presence-absence)
# We will also use this information in examples below
eta <- tcrossprod(cbind(1,mm), cbind(spp_intercepts,spp_slopes)) + 
tcrossprod(true_space_lvs, spp_space_loadings) +
tcrossprod(true_time_lvs, spp_time_loadings)
simy <- matrix(rbinom(num_sites * num_spp, size = 1, 
prob = plogis(eta)), nrow = num_sites)

# Form training and test sets
simy_train <- simy[1:500,]
simy_test <- simy[501:1000,]
dat_train <- dat[1:500,]
dat_test <- dat[501:1000,]
rm(X, eta, xy, simy, true_time_lvs, spp_time_loadings)


# Fit stacked GLM as a baseline
fitstacked <- manyglm(simy_train ~ temp + depth + chla + O2, family = binomial(), data = dat_train)


# Set up spatial basis functions for CBFM -- Most users will start here! 
num_space_basisfunctions <- 20 # Number of spatial basis functions to use
# Training set basis functions
train_space_basisfunctions <- mrts(dat_train[,c("x","y")], num_space_basisfunctions) \%>\% 
as.matrix \%>\%
{.[,-(1)]} # Remove the first intercept column
# Testing set basis functions
test_space_basisfunctions <- mrts(dat_train[,c("x","y")], num_space_basisfunctions) \%>\% 
predict(newx = dat_test[,c("x","y")]) \%>\% 
as.matrix \%>\%
{.[,-c(1)]} 

# Training and test temporal basis functions
num_time_basisfunctions <- 10 # Number of temporal basis functions to use
time_knots <- seq(0, 10, length = num_time_basisfunctions)
time_basisfunctions <- local_basis(manifold = real_line(), loc = as.matrix(time_knots),
scale = rep(2, length(time_knots)), type = "bisquare")
time_basisfunctions <- eval_basis(time_basisfunctions, s = as.matrix(dat$time)) \%>\%
as.matrix
train_time_basisfunctions <- time_basisfunctions[1:500,] 
test_time_basisfunctions <- time_basisfunctions[501:1000,] 
rm(time_basisfunctions, time_knots)

# Fit CBFM with additive spatial and temporal basis functions 
tic <- proc.time()
useformula <- ~ temp + depth + chla + O2
fitcbfm_additive <- CBFM(y = simy_train, formula = useformula, data = dat_train, 
B_space = train_space_basisfunctions, B_time = train_time_basisfunctions, family = binomial(), 
G_control = list(rank = c(5,5)), Sigma_control = list(rank = c(5,5)), control = list(trace = 1))
toc <- proc.time()
toc - tic

 
# Calculate predictions onto test dataset
predictions_stacked <- predict(fitstacked, newdata = dat_test, type = "response")
predictions_cbfm_additive <- predict(fitcbfm_additive, newdata = dat_test, type = "response", 
new_B_space = test_space_basisfunctions, new_B_time = test_time_basisfunctions)

# Evaluation predictions
# Tjur R-squared across species
tjurR2 <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
m1 <- predictions_stacked[which(simy_test[,j] > 0),j] \%>\%
mean(na.rm = TRUE)
m0 <- predictions_stacked[which(simy_test[,j] == 0),j] \%>\%
mean(na.rm = TRUE)
m1 - m0     
}),
cbfm = sapply(1:num_spp, function(j) { 
m1 <- predictions_cbfm_additive[which(simy_test[,j] > 0),j] \%>\%
mean(na.rm = TRUE)
m0 <- predictions_cbfm_additive[which(simy_test[,j] == 0),j] \%>\%
mean(na.rm = TRUE)
m1 - m0     
})
)

boxplot(tjurR2, main = "Tjur-R2", names = c("Stacked GLM", "CBFM (additive)"))

ggplot(tjurR2, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM (additive)", main = "Tjur-R2") +
theme_bw()

# AUC across species
aucs <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
pred <- prediction(predictions_stacked[,j], labels = simy_test[,j]) \%>\%
performance(measure = "auc")  
pred@y.values[[1]]
}),
cbfm = sapply(1:num_spp, function(j) { 
pred <- prediction(predictions_cbfm_additive[,j], labels = simy_test[,j]) \%>\%
performance(measure = "auc") 
pred@y.values[[1]]
})
)

boxplot(aucs, main = "AUC", names = c("Stacked GLM", "CBFM (additive)"))

ggplot(aucs, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM (additive)", main = "AUC") +
theme_bw()


##------------------------------
## **Example 3b: Repeat Example 3a but use a species-specific random intercept for time**
## Simulated from a spatio-temporal latent variable model with random intercept for time
## Please note the data generation process (thus) differs from CBFM.
## The additive CBFM might take a while to fit...grab a cuppa!
##------------------------------
# Consider 10 time points, 100 spatial locations sampled per time point
dat$time <- rep(1:10, each = 100) \%>\% factor
spp_time_variances <- runif(num_spp, 0.5, 2)
spp_time_randint <- sapply(spp_time_variances, function(x) rnorm(10, 0, sd = sqrt(x))) \%>\%
t
mm_time <- model.matrix(~ time - 1, data = dat)

# Simulate spatial multivariate abundance data (presence-absence)
# We will also use this information in examples below
eta <- tcrossprod(cbind(1,mm), cbind(spp_intercepts,spp_slopes)) + 
tcrossprod(true_space_lvs, spp_space_loadings) +
tcrossprod(mm_time, spp_time_randint)
simy <- matrix(rbinom(num_sites * num_spp, size = 1, 
prob = plogis(eta)), nrow = num_sites)

# Form training and test sets
simy_train <- simy[1:500,]
simy_test <- simy[501:1000,]
dat_train <- dat[1:500,]
dat_test <- dat[501:1000,]
rm(eta, mm, mm_time, simy, true_space_lvs, spp_space_loadings)


# Fit stacked GLM as a baseline
fitstacked <- manyglm(simy_train ~ temp + depth + chla + O2, family = binomial(), data = dat_train)


# Set up spatial basis functions for CBFM -- Most users will start here! 
num_space_basisfunctions <- 20 # Number of spatial basis functions to use
# Training set basis functions
train_space_basisfunctions <- mrts(dat_train[,c("x","y")], num_space_basisfunctions) \%>\% 
as.matrix \%>\%
{.[,-(1)]} # Remove the first intercept column
# Testing set basis functions
test_space_basisfunctions <- mrts(dat_train[,c("x","y")], num_space_basisfunctions) \%>\% 
predict(newx = dat_test[,c("x","y")]) \%>\% 
as.matrix \%>\%
{.[,-c(1)]} 

# Training temporal basis functions. For species-specific random intercepts, 
# set up the model matrix reflecting a random intercept for time. Then set up a custom Sigma,
# which in this case will be equal to an identity matrix 
# (since within each species, the random intercepts are drawn independently; see above)
dat_train$time <- factor(dat_train$time) # Re-factor so that it now only has five time points
train_time_basisfunctions <- model.matrix(~ time - 1, data = dat_train)
custom_Sigma_time <- diag(nrow = ncol(train_time_basisfunctions))


# Fit CBFM with additive spatial and temporal basis functions 
tic <- proc.time()
useformula <- ~ temp + depth + chla + O2
fitcbfm_additive <- CBFM(y = simy_train, formula = useformula, data = dat_train, 
B_space = train_space_basisfunctions, B_time = train_time_basisfunctions, family = binomial(), 
G_control = list(rank = c(5,5)), 
Sigma_control = list(rank = c(5,"full"), custom_time = custom_Sigma_time), 
control = list(trace = 1))
toc <- proc.time()
toc - tic


# Calculate predictions onto test dataset
predictions_stacked <- predict(fitstacked, newdata = dat_test, type = "response")
# Note the test data contains completely different time points to the training data, and
# so the test set of temporal basis functions is then just a matrix of zeros. This is 
# analogous to, say, how mgcv handles random effects; see ?smooth.construct.re.smooth.spec
test_time_basisfunctions <- matrix(0, nrow = 500, ncol = ncol(train_time_basisfunctions))
predictions_cbfm_additive <- predict(fitcbfm_additive, newdata = dat_test, type = "response", 
new_B_space = test_space_basisfunctions, new_B_time = test_time_basisfunctions)


# Evaluation predictions
# Tjur R-squared across species
tjurR2 <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
m1 <- predictions_stacked[which(simy_test[,j] > 0),j] \%>\%
mean(na.rm = TRUE)
m0 <- predictions_stacked[which(simy_test[,j] == 0),j] \%>\%
mean(na.rm = TRUE)
m1 - m0     
}),
cbfm = sapply(1:num_spp, function(j) { 
m1 <- predictions_cbfm_additive[which(simy_test[,j] > 0),j] \%>\%
mean(na.rm = TRUE)
m0 <- predictions_cbfm_additive[which(simy_test[,j] == 0),j] \%>\%
mean(na.rm = TRUE)
m1 - m0     
})
)

boxplot(tjurR2, main = "Tjur-R2", names = c("Stacked GLM", "CBFM (additive)"))

ggplot(tjurR2, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM (additive)", main = "Tjur-R2") +
theme_bw()

# AUC across species
aucs <- data.frame(
stacked = sapply(1:num_spp, function(j) { 
pred <- prediction(predictions_stacked[,j], labels = simy_test[,j]) \%>\%
performance(measure = "auc")  
pred@y.values[[1]]
}),
cbfm = sapply(1:num_spp, function(j) { 
pred <- prediction(predictions_cbfm_additive[,j], labels = simy_test[,j]) \%>\%
performance(measure = "auc") 
pred@y.values[[1]]
})
)

boxplot(aucs, main = "AUC", names = c("Stacked GLM", "CBFM (additive)"))

ggplot(aucs, aes(x = stacked, y = cbfm)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM (additive)", main = "AUC") +
theme_bw()


##------------------------------
## **Example 3c: Repeat Example 3a but with tensor product basis functions**
## Please note the data generation process (thus) differs from CBFM.
## To save some time, and for illustrative purposes, we will use the fast method estimating
## the covariance matrices
# Nevertheless, please note this might take quite a while...grab a big cuppa!
##------------------------------
tic <- proc.time()
useformula <- ~ temp + depth + chla + O2
train_st_basisfunctions <- tensorproduct(train_space_basisfunctions, train_time_basisfunctions)
dim(train_st_basisfunctions)

fitcbfm_tensor <- CBFM(y = simy_train, formula = useformula, data = dat_train, 
B_spacetime = train_st_basisfunctions, family = binomial(), 
G_control = list(rank = 10, method = "simple"), 
Sigma_control = list(rank = 10, method = "simple"), control = list(trace = 1))
toc <- proc.time()
toc - tic


test_st_basisfunctions <- tensorproduct(test_space_basisfunctions, test_time_basisfunctions)
predictions_cbfm_tensor <- predict(fitcbfm_tensor, newdata = dat_test, type = "response", 
new_B_spacetime = test_st_basisfunctions)

# Tjur-R2 across species
tjurR2$cbfm_tensor = sapply(1:num_spp, function(j) { 
m1 <- predictions_cbfm_tensor[which(simy_test[,j] > 0),j] \%>\%
mean(na.rm = TRUE)
m0 <- predictions_cbfm_tensor[which(simy_test[,j] == 0),j] \%>\%
mean(na.rm = TRUE)
m1 - m0
})

boxplot(tjurR2, main = "Tjur-R2", 
names = c("Stacked GLM", "CBFM (additive)", "CBFM (tensor)"))

ggplot(tjurR2, aes(x = stacked, y = cbfm_tensor)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM (tensor)", main = "Tjur-R2") +
theme_bw()

# AUC across species
aucs$cbfm_tensor = sapply(1:num_spp, function(j) { 
pred <- prediction(predictions_cbfm_tensor[,j], labels = simy_test[,j]) \%>\%
performance(measure = "auc") 
pred@y.values[[1]]
})

boxplot(aucs, main = "AUC", 
names = c("Stacked GLM", "CBFM (additive)", "CBFM (tensor)"))

ggplot(aucs, aes(x = stacked, y = cbfm_tensor)) +
geom_point() +
geom_abline(intercept = 0, slope = 1, linetype = 2) +
labs(x = "Stacked SDM", y = "CBFM (tensor)", main = "AUC") +
theme_bw()

# As one can see, the tensor product CBFM here performs a lot worse than the additive CBFM.
# This is partly not surprising given that we used a more approximate fitting method for 
# the tensor product CBFM but also because of the additive latent variables underlying the data
# generation process.

# Indeed, both the authors of this package have found that in practice, the additive CBFM 
# oftens tends to perform better than the tensor product CBFM for 
# spatio-temporal multivariate abundance data.
}

}
\references{
Bradley, J. R., Holan, S. H., and Wikle, C. K. (2018). Computationally efficient multivariate spatio-temporal models for high-dimensional count-valued data (with discussion). Bayesian Analysis, 13, 253-310.

Breslow, N. E., and Clayton, D. G. (1993). Approximate inference in generalized linear mixed models. Journal of the American statistical Association, 88, 9-25.

Brooks, M. E., Kristensen, K., Van Benthem, K. J., Magnusson, A., Berg, C. W., Nielsen, A., and Bolker, B. M. (2017). glmmTMB balances speed and flexibility among packages for zero-inflated generalized linear mixed modeling. The R journal, 9, 378-400.

Cressie, N., and Johannesson, G. (2008). Fixed rank kriging for very large spatial data sets. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 70, 209-226.

Green, P. J. (1984). Iteratively reweighted least squares for maximum likelihood estimation, and some robust and resistant alternatives. Journal of the Royal Statistical Society: Series B (Methodological), 46, 149-170.

Guisan, A., Edwards Jr, T. C., and Hastie, T. (2002). Generalized linear and generalized additive models in studies of species distributions: setting the scene. Ecological modelling, 157, 89-100.

Hefley, T. J., Broms, K. M., Brost, B. M., Buderman, F. E., Kay, S. L., Scharf, H. R., and Hooten, M. B. (2017). The basis function approach for modeling autocorrelation in ecological data. Ecology, 98, 632-646.

Hui, F. K. C. (2016). boral-Bayesian ordination and regression analysis of multivariate abundance data in R. Methods in Ecology and Evolution, 7, 744-750.

Kristensen, K., Nielsen, A., Berg, C. W., Skaug, H., and Bell, B. M. (2016). TMB: Automatic Differentiation and Laplace Approximation. Journal of Statistical Software, 70, 1-21.

Niku, J., Hui, F. K.C., Taskinen, S., and Warton, D. I. (2019). gllvm: Fast analysis of multivariate abundance data with generalized linear latent variable models in R. Methods in Ecology and Evolution, 10, 2173-2182.

Ovaskainen, O., and Abrego, N. (2020). Joint species distribution modelling: with applications in R. Cambridge University Press.

Pollock, L. J., Tingley, R., Morris, W. K., Golding, N., O'Hara, R. B., Parris, K. M., Vesk, P. A., and McCarthy, M. A. (2014). Understanding cooccurrence by modelling species simultaneously with a Joint Species Distribution Model (JSDM). Methods in Ecology and Evolution, 5, 397-406.

Shirota, S., Gelfand, A. E., & Banerjee, S. (2019). Spatial joint species distribution modeling using Dirichlet processes. Statistica Sinica, 29, 1127-1154.

Thorson, J. T., Ianelli, J. N., Larsen, E. A., Ries, L., Scheuerell, M. D., Szuwalski, C., and Zipkin, E. F. (2016). Joint dynamic species distribution models: a tool for community ordination and spatio-temporal monitoring. Global Ecology and Biogeography, 25, 1144-1158.

Thorson, J. T. (2019). Guidance for decisions using the Vector Autoregressive Spatio-Temporal (VAST) package in stock, ecosystem, habitat and climate assessments. Fisheries Research, 210, 143-161.

Tikhonov, G., Opedal, O. H., Abrego, N., Lehikoinen, A., de Jonge, M. M., Oksanen, J., and Ovaskainen, O. (2020). Joint species distribution modelling with the R-package Hmsc. Methods in ecology and evolution, 11, 442-447.

Tzeng, S., and Huang, H. C. (2018). Resolution adaptive fixed rank kriging. Technometrics, 60, 198-208.

Wikle, C. K., Zammit-Mangion, A., and Cressie, N. (2019). Spatio-temporal Statistics with R. CRC Press.

Warton, D. I., Blanchet, F. G., O'Hara, R. B., Ovaskainen, O., Taskinen, S., Walker, S. C., and Hui, F. K. C. (2015). So many variables: joint modeling in community ecology. Trends in Ecology and Evolution, 30, 766-779.

Warton, D. I., Blanchet, F. G., O'Hara, R., Ovaskainen, O., Taskinen, S., Walker, S. C., and Hui, F. K. C. (2016). Extending joint models in community ecology: A response to Beissinger et al. Trends in ecology & evolution, 31, 737-738.

Wood, S. N. (2011). Fast stable restricted maximum likelihood and marginal likelihood estimation of semiparametric generalized linear models. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 73, 3-36.

Wood, S. N. (2017). Generalized additive models: An introduction with R. CRC press.

Zammit-Mangion, A., and Cressie, N. (2017). FRK: An R package for spatial and spatio-temporal prediction with large datasets. arXiv preprint arXiv:1705.08105.

Cressie, N., Sainsbury-Dale, M., and Zammit-Mangion, A. (2021). Basis-Function Models in Spatial Statistics. Annual Review of Statistics and Its Application, 9.
}
\seealso{
\code{\link[=corX]{corX()}} for calculating between-species (cross-)correlations due to measured covariates, \code{\link[=corB]{corB()}} for calculating residual between-species (cross-)correlations due to the basis functions, \code{\link[=fitted.CBFM]{fitted.CBFM()}} for extracting the fitted values from a CBFM fit, \code{\link[=influence.CBFM]{influence.CBFM()}} for calculating some basic influence measures from a CBFM fit, \code{\link[=ordinate.CBFM]{ordinate.CBFM()}} for an \emph{ad-hoc} approach to constructing spatio-temporal ordinations from a CBFM fit, \code{\link[=plot.CBFM]{plot.CBFM()}} for basic residual diagnostics from a CBFM fit, \code{\link[=predict.CBFM]{predict.CBFM()}} for constructing predictions from a CBFM fit, \code{\link[=residuals.CBFM]{residuals.CBFM()}} for calculating residuals from a CBFM fit, \code{\link[=simulate.CBFM]{simulate.CBFM()}} for simulating spatio-temporal multivariate abundance data from a CBFM fit, \code{\link[=summary.CBFM]{summary.CBFM()}} for summaries including standard errors and confidence intervals, and \code{\link[=varpart]{varpart()}} for variance partitioning of a CBFM fit.
}
\author{
Francis K.C. Hui \href{mailto:fhui28@gmail.com}{fhui28@gmail.com}, Chris Haak
}
\section{Warning}{
\enumerate{
\item CBFMs are designed for \emph{spatio-temporal} multivariate abundance data, such that you can sensibly construct basis functions from the space-time coordinate of each observational unit. \strong{Please do not use them for data that are not spatially or temporally indexed}. We recommend you fit standard LVMs in those scenarios, such that made available in \code{\link[gllvm:gllvm]{gllvm::gllvm()}}, \code{\link[boral:boral]{boral::boral()}}, and \code{\link[Hmsc:sampleMcmc]{Hmsc::sampleMcmc()}}.
\item Not for some distributions it is not the mean of the entire distribution which is modeled. For example, in zero-inflated distributions it is the mean of the non-zero-inflated component that is modeled with the regression model described above. In zero-truncated distributions, it is the mean of the base count distribution that is modeled with the regression model described above.
\item Not all (in fact, not many) of the smoothing available that are available in \code{\link[mgcv:gam.models]{mgcv::gam.models()}} have been fully tested out, so please be aware that some make not work well, if at all!
\item As mentioned above, all standard errors and thus inference are currently computed without considering uncertainty in estimation of covariance \eqn{\Sigma} and correlation matrices \eqn{G}, as well as the any dispersion/power parameters, analogous to default settings in \code{\link[mgcv:summary.gam]{mgcv::summary.gam()}}. This can lead to standard errors that are potentially too small, so please keep this in mind. Also, the current estimation approach does not provide uncertainty quantification of \eqn{\Sigma} and \eqn{G}.
\item The returned outputs \code{all_parametric_estimates} and \code{all_smooth_effects} can be \emph{very} large data frames!
}
}
\section{CBFM is not working for my data?!}{

Once you have finished grumbling about the package and its developer, please brew some tea and make yourself comfy...debugging takes a while!

As with any real-life statistical modeling problem, it is almost impossible to determine what the source of the issue is without looking at the data and specific application first hand. Therefore, we can only provide some general avenues to pursue below as a first step towards making CBFM run on your data, and of course we can not guarantee that the output produced from this debugging makes any ecological sense!
\itemize{
\item An initial thing to try is to bump up the number of inner iterations i.e., \code{control$inner_maxit} from the default of 1 to something like 10, 20 or even higher. This will give more opportunities for the inner estimation component of the PQL algorithm (where all regression and smoothing coefficients are updated) to try converge to a stable point, before proceeding to estimating the other model parameters.
\item Sometimes the starting values that CBFM constructs are not that great! A common situation where this occurs is when smoothers are employed in \code{formula} and the data are (extremely) overdispersed or show signs of complete or quasi-separation. A simple way to try and break out of bad automated starting values is to make use of the \code{control$initial_betas_dampen} argument, which as the name suggests, dampens the starting estimated coefficients from potentially extreme magnitudes, and can facilitate the underlying PQL estimation algorithm to "get going".
\item Alternatively, supplying your own "wisely chosen" starting values is never a bad thing, plus it can often help to speed up the fitting process. In our experience, often a decent way to obtain starting values is to fit stacked GAMs using \code{\link[mgcv:gam]{mgcv::gam()}} with the same formula as you will use in \code{formula}, plus smoothing terms to account for space and/or time. Some template code is provided as follows:
}\preformatted{manygam <- foreach::foreach(j = 1:num_spp) \%dopar\%
    gam(response ~ s(temp) + s(depth) + s(chla) + s(O2) + s(x,y), data = data.frame(response = simy_train[,j], dat_train), family = xxx)
start_params = list(betas = t(sapply(manygam, coef)[1:37,])) # Or as appropriate the number of coefficients excluding the spatial-temporal smoothing terms
}
\itemize{
\item Analogously, the argument \code{control$subsequent_betas_dampen} can be used to dampen the values obtained for the species-specific regression coefficients during subsequent running of the PQL estimation algorithm. Basically, it is an \emph{ad-hoc} solution to when updates potentially fail due to e.g., overfitting causing coefficients to become extremely large in magnitude.
\item If, after multiple attempts at debugging and you CBF'd anymore (pun-intended), then you can post the issue up on \href{https://github.com/fhui28/CBFM}{CBFM Github page} \emph{if} you think there is a genuine bug in the package. Otherwise, you can email the authors of this package on potential general statistical modeling questions, although we may not be able to get to them soon let along have the time to get to them at all (we are paid to be statistical consultants...apologies in advance!). Please do not post general statistical modeling issues on Github issues, as they will likely be ignored or deleted without prior consent.
}
}
